import streamlit as st
import os, json, time, concurrent.futures
from collections import Counter
import pypdf
from docx import Document
import ebooklib
from ebooklib import epub
from bs4 import BeautifulSoup
from google import genai
from google.genai import types
from pyvis.network import Network
import networkx as nx

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="DeepGraph Pro",
    layout="wide",
    page_icon="â˜ï¸",
    initial_sidebar_state="expanded"
)

# --- æœªæ¥æ„Ÿæ ·å¼ ---
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');
:root {
    --bg1: #0f172a; --bg2: #111827; --card: rgba(255,255,255,0.08);
    --border: rgba(255,255,255,0.18); --primary: #5b8cff; --accent: #00d1ff;
}
.stApp {
    background: radial-gradient(120% 120% at 20% 20%, rgba(91,140,255,0.25), transparent 40%),
                radial-gradient(100% 100% at 80% 0%, rgba(0,209,255,0.18), transparent 45%),
                linear-gradient(135deg, var(--bg1), var(--bg2));
    color: #e5e7eb; font-family: 'Inter', sans-serif;
}
.glass-card {
    background: var(--card); border: 1px solid var(--border);
    backdrop-filter: blur(16px) saturate(1.4); -webkit-backdrop-filter: blur(16px) saturate(1.4);
    box-shadow: 0 20px 60px rgba(0,209,255,0.16), 0 8px 24px rgba(0,0,0,0.28);
    border-radius: 16px; padding: 20px 20px 16px; transition: all 180ms ease;
}
.glass-card:hover { transform: translateY(-2px); box-shadow: 0 16px 40px rgba(0,0,0,0.32), 0 20px 60px rgba(0,209,255,0.16); }
.stButton > button, .stDownloadButton > button {
    background: linear-gradient(120deg, var(--primary), var(--accent));
    color:#fff; border:none; border-radius:10px; height:44px; font-weight:700; letter-spacing:0.2px;
    box-shadow:0 10px 30px rgba(91,140,255,0.35); transition:all 150ms ease;
}
.stButton > button:hover, .stDownloadButton > button:hover { filter: brightness(1.06); box-shadow:0 14px 34px rgba(0,209,255,0.35); transform: translateY(-1px); }
.stTextInput > div > div > input, .stTextArea > div > textarea, .stSelectbox > div > div > div {
    background: rgba(255,255,255,0.06) !important; border: 1px solid var(--border) !important;
    border-radius: 10px !important; color: #e5e7eb !important;
}
.stProgress > div > div { background: rgba(255,255,255,0.08); border-radius: 999px; }
.stProgress > div > div > div { background: linear-gradient(120deg, var(--primary), var(--accent)); box-shadow: 0 4px 16px rgba(91,140,255,0.4); }
</style>
""", unsafe_allow_html=True)

# --- çŠ¶æ€ç®¡ç† ---
if 'processed' not in st.session_state: st.session_state.processed = False
if 'graph_html' not in st.session_state: st.session_state.graph_html = ""
if 'report_txt' not in st.session_state: st.session_state.report_txt = ""
if 'truncated' not in st.session_state: st.session_state.truncated = False

# --- å‚æ•° ---
MAX_WORKERS = 4
CHUNK_LEN = 12000
OVERLAP = 800
BAN_REL = {"æ˜¯","æœ‰","å­˜åœ¨","åŒ…å«","æ¶‰åŠ"}  # è¿‡äºç©ºæ³›çš„è°“è¯­ï¼Œå¯è°ƒæ•´
ALIASES = {
    "é‚“å°å¹³": ["å°å¹³", "é‚“å…¬"],
    "æ¯›æ³½ä¸œ": ["æ¯›ä¸»å¸­", "æ¯›æ³½ä¸œä¸»å¸­"],
    "ä¹ è¿‘å¹³": ["ä¹ ", "è¿‘å¹³"],
    # å¯ç»§ç»­æ‰©å±•é‡è¦ä¸»ä½“/æœºæ„/äº‹ä»¶
}

COLORS = {
    "HighRisk": "#ff6b6b",
    "Person": "#5b8cff",
    "Outcome": "#94a3b8",
    "Faction": "#a78bfa",
    "NoRisk": "#22c55e",
    "Unknown": "#adb5bd"
}
STYLE = {
    "active": {"color": "#adb5bd", "dashes": False},
    "passive": {"color": "#6c757d", "dashes": True}
}

PROMPT = """
ã€ä»»åŠ¡ã€‘æå– SVOï¼ˆæœ‰å‘ï¼‰ä¸‰å…ƒç»„ã€‚Head=å‘èµ·è€…ï¼ˆä¸»åŠ¨ï¼‰ï¼ŒTail=æ‰¿å—è€…ï¼ˆè¢«åŠ¨ï¼‰ã€‚
ã€æ–¹å‘ã€‘direction=activeï¼ˆHead ä¸»åŠ¨ä½œç”¨ Tailï¼‰æˆ– passiveï¼ˆHead è¢« Tail ä½œç”¨ï¼‰ã€‚
ã€åˆ†ç±»ã€‘type âˆˆ [HighRisk, Faction, Person, Outcome, NoRisk]ï¼Œä¸ç¡®å®šç”¨ Unknownã€‚
ã€æ ¼å¼ã€‘JSON æ•°ç»„ï¼š
[{"head": "...", "type_head": "...", "relation": "ç²¾ç¡®è°“è¯­", "tail": "...", "type_tail": "...", "direction": "active|passive"}]
ã€çº¦æŸã€‘
1) ä¸éšæ„åˆå¹¶è°“è¯­ï¼Œä¿ç•™åŠ¨è¯åŸä¹‰ã€‚
2) æ•æ„Ÿä¸»ä½“å®Œæ•´è¡¨è¿°ï¼Œä¸å¼±åŒ–ã€‚
3) æ— æœ‰æ•ˆä¸‰å…ƒç»„åˆ™è¿”å› []ã€‚
æ–‡æœ¬ï¼ˆæˆªæ–­ï¼‰ï¼š{text}...
"""

# --- è¾…åŠ©å‡½æ•° ---
def split_text(txt, size=CHUNK_LEN, overlap=OVERLAP):
    out = []
    n = len(txt); i = 0
    while i < n:
        out.append(txt[i:i+size])
        i += size - overlap
    return out

def extract_text(file_path):
    ext = file_path.lower().split('.')[-1]
    text = ""
    try:
        if ext == 'pdf':
            reader = pypdf.PdfReader(file_path)
            for page in reader.pages: text += (page.extract_text() or "") + "\n"
        elif ext == 'epub':
            book = epub.read_epub(file_path)
            for item in list(book.get_items_of_type(ebooklib.ITEM_DOCUMENT)):
                soup = BeautifulSoup(item.get_content(), 'html.parser')
                text += soup.get_text() + "\n"
        elif ext in ['docx', 'doc']:
            doc = Document(file_path)
            text = "\n".join([p.text for p in doc.paragraphs])
        else:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                text = f.read()
    except Exception as e:
        print(f"[extract] {file_path} error: {e}")
    return text

def canonicalize(name: str) -> str:
    if not name: return name
    name = name.strip()
    for canon, alias_list in ALIASES.items():
        if name == canon or name in alias_list:
            return canon
    n = "".join(ch for ch in name if ch.isalnum())
    for canon, alias_list in ALIASES.items():
        for a in [canon, *alias_list]:
            if n == "".join(ch for ch in a if ch.isalnum()):
                return canon
    return name

@st.cache_resource
def get_client(api_key): return genai.Client(api_key=api_key)

def analyze_svo(chunk_data, client, model):
    i, text = chunk_data
    prompt = PROMPT.format(text=text[:1200])
    try:
        resp = client.models.generate_content(model=model, contents=prompt)
        raw = resp.text.replace("```json","").replace("```","").strip()
        s, e = raw.find('['), raw.rfind(']')+1
        return json.loads(raw[s:e]) if s != -1 else []
    except Exception as e:
        print(f"[chunk {i}] error: {e}")
        return []

def trim_graph(raw, max_nodes=300, min_nodes=50):
    cnt = Counter()
    for it in raw:
        cnt[it["head"]] += 1
        cnt[it["tail"]] += 1
    top_nodes = {n for n, _ in cnt.most_common(max_nodes)}
    trimmed = [it for it in raw if it["head"] in top_nodes and it["tail"] in top_nodes]
    if len(top_nodes) < min_nodes:
        return raw, False
    if len(top_nodes) > max_nodes:
        return trimmed, True
    return trimmed, False

# --- æ ¸å¿ƒæµç¨‹ ---
def main_run(files, api_key, model):
    chunks = []
    for f in files:
        txt = extract_text(f)
        if len(txt) > 100:
            for i, s in enumerate(split_text(txt)):
                chunks.append((f"{f.name}-{i}", s))

    if not chunks: return None, "âŒ æ–‡ä»¶å†…å®¹ä¸ºç©ºæˆ–è¯»å–å¤±è´¥", False

    st.info(f"ğŸš€ äº‘ç«¯å¼•æ“å¯åŠ¨ï¼šåˆ†æ {len(chunks)} ä¸ªç‰‡æ®µ...")
    bar = st.progress(0)
    raw = []

    client = get_client(api_key)
    max_workers = min(MAX_WORKERS, len(chunks))
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as exe:
        futures = [exe.submit(analyze_svo, c, client, model) for c in chunks]
        for i, f in enumerate(concurrent.futures.as_completed(futures)):
            if res := f.result(): raw.extend(res)
            bar.progress((i+1)/len(chunks))

    if not raw: return None, "âŒ æœªæå–åˆ°æ•°æ®ï¼Œè¯·æ£€æŸ¥ API Key æˆ–æ¨¡å‹æƒé™", False

    # å½’ä¸€ + è°“è¯­è¿‡æ»¤
    norm = []
    for it in raw:
        h, t, r = canonicalize(it.get("head")), canonicalize(it.get("tail")), it.get("relation")
        if not h or not t or not r: continue
        if r in BAN_REL: continue
        it["head"], it["tail"] = h, t
        norm.append(it)

    # èŠ‚ç‚¹è£å‰ª
    norm, truncated = trim_graph(norm, max_nodes=300, min_nodes=50)

    # æ„å›¾
    G = nx.DiGraph()
    for item in norm:
        h, t, r = item["head"], item["tail"], item["relation"]
        ht, tt = item.get("type_head", "Person"), item.get("type_tail", "Person")
        direction = item.get("direction", "active")
        edge_style = STYLE.get(direction, STYLE["active"])
        G.add_node(h, label=h, color=COLORS.get(ht, "#5b8cff"), size=20)
        G.add_node(t, label=t, color=COLORS.get(tt, "#5b8cff"), size=20)
        label = r if len(r) <= 28 else r[:25] + "..."
        G.add_edge(h, t, label=label, color=edge_style["color"], smooth=True, arrows="to", dashes=edge_style["dashes"])

    # æŠ¥å‘Š
    rpt = "# DeepGraph Report\n\n"
    rpt += f"- èŠ‚ç‚¹æ•°: {len(G.nodes())}\n- è¾¹æ•°: {len(G.edges())}\n"
    type_cnt = Counter([n[1].get('color') for n in G.nodes(data=True)])
    if truncated:
        rpt += "- æ³¨æ„ï¼šèŠ‚ç‚¹å·²æˆªæ–­åˆ°å‰ 300 ä¸ªæœ€ç›¸å…³èŠ‚ç‚¹ã€‚\n"
    rpt += "- ç±»å‹è®¡æ•°ï¼ˆæŒ‰é¢œè‰²ï¼‰: " + ", ".join([f"{k}:{v}" for k,v in type_cnt.items()]) + "\n\n"
    rpt += "## ä¸‰å…ƒç»„\n"
    for u, v, d in G.edges(data=True):
        rpt += f"{u} --[{d.get('label','')}]--> {v}\n"

    return G, rpt, truncated

# --- ç•Œé¢ ---
st.title("DeepGraph Pro (Cloud Edition)")

with st.sidebar:
    st.header("Settings")
    st.success("âœ… äº‘ç«¯ç¯å¢ƒå·²å°±ç»ª")
    api_key = st.text_input("Google API Key", type="password")
    model_id = st.text_input("Model ID", value="gemini-2.0-flash-exp")
    if st.button("ğŸ” Check Available Models"):
        if not api_key:
            st.error("Please enter API Key first")
        else:
            try:
                client = genai.Client(api_key=api_key)
                models = [m.name for m in client.models.list() if "gemini" in m.name]
                st.write(models)
            except Exception as e:
                st.error(f"Error: {e}")

col1, col2 = st.columns([1, 2.2])

with col1:
    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
    files = st.file_uploader("Upload Files (PDF/DOCX/TXT)", accept_multiple_files=True)
    st.markdown("<br>", unsafe_allow_html=True)
    start = st.button("ğŸš€ Start Analysis")
    st.markdown('</div>', unsafe_allow_html=True)

    if st.session_state.processed:
        st.download_button("Download Graph HTML", st.session_state.graph_html, "graph.html", "text/html")
        st.download_button("Download Report TXT", st.session_state.report_txt, "report.txt", "text/plain")

with col2:
    # çŠ¶æ€æ¡
    status = "Ready"
    if start: status = "Running"
    if st.session_state.processed: status = "Done"
    st.markdown(
        f"<div class='glass-card' style='padding:12px 16px; display:flex; gap:8px; align-items:center;'>"
        f"<span style='padding:4px 10px; border-radius:999px; background:rgba(0,209,255,0.16); color:#00d1ff; font-weight:700;'>{status}</span>"
        f"<span style='color:#cbd5e1;'>äº‘ç«¯ SVO å›¾è°±åˆ†æ</span>"
        "</div>", unsafe_allow_html=True
    )

    if start:
        if not api_key or not files:
            st.error("è¯·å¡«å…¥ API Key å¹¶ä¸Šä¼ æ–‡ä»¶")
        else:
            with st.spinner("Analyzing on Cloud..."):
                G, rpt, truncated = main_run(files, api_key, model_id)
                if G:
                    net = Network(height="700px", width="100%", bgcolor="#0f172a", font_color="#e5e7eb", directed=True)
                    net.from_nx(G)
                    st.session_state.graph_html = net.generate_html()
                    st.session_state.report_txt = rpt
                    st.session_state.processed = True
                    st.session_state.truncated = truncated
                    st.rerun()
                elif rpt: st.error(rpt)

    if st.session_state.processed:
        if st.session_state.truncated:
            st.warning("âš ï¸ èŠ‚ç‚¹å·²æˆªæ–­è‡³å‰ 300 ä¸ªæœ€ç›¸å…³èŠ‚ç‚¹")
        st.components.v1.html(st.session_state.graph_html, height=700)
