import streamlit as st
import os, json, io, tempfile, re
from typing import List, Optional
from enum import Enum
from collections import defaultdict
import pypdf
from docx import Document
import ebooklib
from ebooklib import epub
from bs4 import BeautifulSoup
from google import genai
from google.genai import types
from pydantic import BaseModel, Field
from pyvis.network import Network
import networkx as nx

st.set_page_config(page_title="è§£ä¹¦å®¢", layout="wide", page_icon="ğŸ“–", initial_sidebar_state="collapsed")

# ============================================
# å…šå²æ–‡çŒ®ç ”ç©¶é™¢é£æ ¼ - ä¸­å›½çº¢ + åº„é‡ä¸¥è‚ƒ
# ============================================
st.markdown("""
<style>
    /* å…¬æ–‡å­—ä½“ */
    @import url('https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;500;600;700&family=Noto+Sans+SC:wght@400;500;700&display=swap');
    
    :root {
        /* ä¸­å›½çº¢é…è‰² */
        --china-red: #C41E3A;
        --china-red-dark: #A01830;
        --china-red-light: #E8384F;
        --china-red-bg: rgba(196, 30, 58, 0.08);
        --gold: #D4AF37;
        --gold-light: #F5E6C4;
        
        /* èƒŒæ™¯è‰² */
        --bg-body: #ffffff;
        --bg-card: #ffffff;
        --bg-subtle: #fafafa;
        --bg-header: var(--china-red);
        
        /* æ–‡å­—è‰² */
        --text-primary: #1a1a1a;
        --text-secondary: #4a4a4a;
        --text-muted: #7a7a7a;
        --text-light: #ffffff;
        
        /* è¾¹æ¡† */
        --border: #e5e5e5;
        --border-red: var(--china-red);
        
        /* é˜´å½± */
        --shadow-sm: 0 1px 3px rgba(0,0,0,0.08);
        --shadow-md: 0 4px 12px rgba(0,0,0,0.1);
        --shadow-red: 0 4px 16px rgba(196, 30, 58, 0.2);
        
        /* åœ†è§’ - å…šæ”¿é£æ ¼ç”¨è¾ƒå°åœ†è§’ */
        --radius-sm: 4px;
        --radius-md: 6px;
        --radius-lg: 8px;
        
        /* å…¬æ–‡å­—ä½“ */
        --font-title: "Noto Serif SC", "SimSun", "å®‹ä½“", serif;
        --font-body: "Noto Sans SC", "Microsoft YaHei", "å¾®è½¯é›…é»‘", sans-serif;
        --font-quote: "KaiTi", "æ¥·ä½“", "STKaiti", serif;
    }
    
    .stApp {
        background: var(--bg-body) !important;
    }
    
    #MainMenu, footer, header {visibility: hidden; height: 0;}
    .stDeployButton, [data-testid="stToolbar"], [data-testid="stDecoration"] {display: none;}
    
    /* å…¨å±€å­—ä½“ */
    * {
        font-family: var(--font-body);
        font-weight: 400;
        -webkit-font-smoothing: antialiased;
        line-height: 1.8;
    }
    
    /* æ ‡é¢˜ç”¨å®‹ä½“ */
    h1, h2, h3 {
        font-family: var(--font-title) !important;
        font-weight: 600 !important;
        color: var(--text-primary) !important;
        letter-spacing: 0.02em !important;
    }
    
    h1 { font-size: 26px !important; }
    h2 { font-size: 22px !important; }
    h3 { font-size: 18px !important; }
    
    /* æ­£æ–‡ */
    p, span, label, div {
        font-family: var(--font-body);
        color: var(--text-secondary);
    }
    
    /* ========== Hero åŒºåŸŸ ========== */
    .hero {
        text-align: center;
        padding: 100px 24px 50px;
        background: linear-gradient(180deg, var(--china-red-bg) 0%, var(--bg-body) 100%);
    }
    
    .hero-badge {
        display: inline-block;
        background: var(--china-red);
        color: white;
        padding: 6px 16px;
        font-size: 13px;
        font-weight: 500;
        letter-spacing: 0.1em;
        margin-bottom: 20px;
    }
    
    .hero h1 {
        font-family: var(--font-title) !important;
        font-size: 42px !important;
        font-weight: 700 !important;
        color: var(--china-red) !important;
        margin-bottom: 12px !important;
        letter-spacing: 0.15em !important;
    }
    
    .hero h2 {
        font-size: 16px !important;
        font-weight: 400 !important;
        color: var(--text-muted) !important;
        margin-bottom: 8px !important;
        letter-spacing: 0.05em !important;
    }
    
    .hero-desc {
        color: var(--text-secondary);
        font-size: 14px;
        max-width: 500px;
        margin: 0 auto;
        line-height: 1.8;
    }
    
    /* ========== çº¢è‰²æŒ‰é’® ========== */
    .stButton > button {
        background: var(--china-red) !important;
        color: white !important;
        border: none !important;
        border-radius: var(--radius-sm) !important;
        padding: 10px 28px !important;
        font-size: 14px !important;
        font-weight: 500 !important;
        letter-spacing: 0.05em !important;
        transition: all 0.2s ease !important;
        box-shadow: var(--shadow-sm) !important;
    }
    
    .stButton > button:hover {
        background: var(--china-red-dark) !important;
        box-shadow: var(--shadow-red) !important;
        transform: translateY(-1px) !important;
    }
    
    .stButton > button:active {
        transform: translateY(0) !important;
    }
    
    /* ========== æ–‡ä»¶ä¸Šä¼ åŒº ========== */
    .stFileUploader {
        background: var(--bg-card);
        border: 2px dashed var(--china-red);
        border-radius: var(--radius-md);
        padding: 40px 32px;
        transition: all 0.2s ease;
    }
    
    .stFileUploader:hover {
        background: var(--china-red-bg);
        border-style: solid;
    }
    
    /* ========== è¾“å…¥æ¡† ========== */
    .stTextInput > div > div > input,
    .stTextArea > div > div > textarea,
    .stSelectbox > div > div > div {
        border-radius: var(--radius-sm) !important;
        border: 1px solid var(--border) !important;
        padding: 10px 14px !important;
        font-size: 14px !important;
        background: var(--bg-card) !important;
        color: var(--text-primary) !important;
        transition: all 0.2s ease !important;
    }
    
    .stTextInput > div > div > input:focus,
    .stTextArea > div > div > textarea:focus {
        border-color: var(--china-red) !important;
        box-shadow: 0 0 0 2px var(--china-red-bg) !important;
    }
    
    /* ========== å¡ç‰‡æ ·å¼ ========== */
    .dang-card {
        background: var(--bg-card);
        border: 1px solid var(--border);
        border-left: 4px solid var(--china-red);
        padding: 20px 24px;
        margin: 12px 0;
        transition: all 0.2s ease;
    }
    
    .dang-card:hover {
        box-shadow: var(--shadow-md);
        border-left-color: var(--china-red-dark);
    }
    
    .dang-card-title {
        font-family: var(--font-title);
        font-size: 16px;
        font-weight: 600;
        color: var(--text-primary);
        margin-bottom: 8px;
        display: flex;
        align-items: center;
        gap: 8px;
    }
    
    .dang-card-title::before {
        content: 'â—†';
        color: var(--china-red);
        font-size: 10px;
    }
    
    /* ========== é£é™©æ ‡ç­¾ ========== */
    .risk-safe { 
        background: #e8f5e9; 
        color: #2e7d32;
        border: 1px solid #a5d6a7;
    }
    .risk-controversial { 
        background: #fff8e1; 
        color: #f57c00;
        border: 1px solid #ffcc80;
    }
    .risk-high { 
        background: #ffebee; 
        color: #c62828;
        border: 1px solid #ef9a9a;
    }
    
    .risk-tag {
        display: inline-block;
        padding: 3px 10px;
        font-size: 12px;
        font-weight: 500;
    }
    
    /* ========== ç±»å‹æ ‡ç­¾ ========== */
    .type-tag {
        display: inline-block;
        padding: 2px 8px;
        font-size: 11px;
        font-weight: 500;
        margin-right: 6px;
        background: var(--bg-subtle);
        color: var(--text-secondary);
        border: 1px solid var(--border);
    }
    
    .type-person { background: #ffebee; color: #c62828; border-color: #ef9a9a; }
    .type-location { background: #e3f2fd; color: #1565c0; border-color: #90caf9; }
    .type-org { background: #e8f5e9; color: #2e7d32; border-color: #a5d6a7; }
    .type-doc { background: #f3e5f5; color: #7b1fa2; border-color: #ce93d8; }
    .type-concept { background: #fff8e1; color: #f57c00; border-color: #ffcc80; }
    
    /* ========== äº‹ä»¶æ ‡ç­¾ ========== */
    .event-meeting { background: #e3f2fd; color: #1565c0; border-color: #90caf9; }
    .event-conflict { background: #ffebee; color: #c62828; border-color: #ef9a9a; }
    .event-speech { background: #e8f5e9; color: #2e7d32; border-color: #a5d6a7; }
    .event-policy { background: #f3e5f5; color: #7b1fa2; border-color: #ce93d8; }
    .event-movement { background: #fff8e1; color: #f57c00; border-color: #ffcc80; }
    
    /* ========== äº‹ä»¶å¡ç‰‡ ========== */
    .event-card {
        background: var(--bg-card);
        border: 1px solid var(--border);
        border-left: 4px solid var(--china-red);
        padding: 16px 20px;
        margin: 10px 0;
        transition: all 0.2s ease;
    }
    
    .event-card:hover {
        box-shadow: var(--shadow-sm);
    }
    
    .event-title {
        font-family: var(--font-title);
        font-size: 15px;
        font-weight: 600;
        color: var(--text-primary);
        margin-bottom: 6px;
    }
    
    .event-meta {
        font-size: 13px;
        color: var(--text-muted);
        margin-bottom: 8px;
    }
    
    .event-desc {
        font-family: var(--font-quote);
        font-size: 14px;
        color: var(--text-secondary);
        line-height: 1.7;
    }
    
    /* ========== Expander ========== */
    .streamlit-expanderHeader {
        background: var(--bg-subtle) !important;
        border: 1px solid var(--border) !important;
        font-weight: 500 !important;
        color: var(--text-primary) !important;
    }
    
    /* ========== Metrics ========== */
    [data-testid="stMetricValue"] {
        font-family: var(--font-title) !important;
        font-size: 32px !important;
        font-weight: 700 !important;
        color: var(--china-red) !important;
    }
    
    [data-testid="stMetricLabel"] {
        font-size: 13px !important;
        color: var(--text-muted) !important;
    }
    
    /* ========== Multiselect ========== */
    .stMultiSelect [data-baseweb="tag"] {
        background: var(--china-red) !important;
        border-radius: 2px !important;
    }
    
    /* ========== Slider ========== */
    .stSlider [data-baseweb="slider"] [role="slider"] {
        background: var(--china-red) !important;
    }
    
    .stSlider [data-baseweb="slider"] > div > div {
        background: var(--china-red) !important;
    }
    
    /* ========== Progress ========== */
    .stProgress > div > div {
        background: var(--china-red) !important;
    }
    
    /* ========== Tabs ========== */
    .stTabs [data-baseweb="tab-list"] {
        gap: 0;
        border-bottom: 2px solid var(--border);
    }
    
    .stTabs [data-baseweb="tab"] {
        border-radius: 0 !important;
        padding: 12px 24px !important;
        font-weight: 500 !important;
    }
    
    .stTabs [aria-selected="true"] {
        background: transparent !important;
        border-bottom: 3px solid var(--china-red) !important;
        color: var(--china-red) !important;
    }
    
    /* ========== Scrollbar ========== */
    ::-webkit-scrollbar {
        width: 8px;
        height: 8px;
    }
    
    ::-webkit-scrollbar-track {
        background: var(--bg-subtle);
    }
    
    ::-webkit-scrollbar-thumb {
        background: #ccc;
        border-radius: 4px;
    }
    
    ::-webkit-scrollbar-thumb:hover {
        background: var(--china-red);
    }
    
    /* ========== åˆ†éš”çº¿ ========== */
    .dang-divider {
        border: none;
        border-top: 1px solid var(--border);
        margin: 24px 0;
    }
    
    /* ========== åŒºå—æ ‡é¢˜ ========== */
    .section-header {
        display: flex;
        align-items: center;
        gap: 10px;
        margin-bottom: 16px;
        padding-bottom: 10px;
        border-bottom: 2px solid var(--china-red);
    }
    
    .section-header::before {
        content: '';
        width: 4px;
        height: 20px;
        background: var(--china-red);
    }
    
    .section-title {
        font-family: var(--font-title);
        font-size: 18px;
        font-weight: 600;
        color: var(--text-primary);
        margin: 0;
    }
</style>
""", unsafe_allow_html=True)

# ============================================
# Pydantic Schema - Event-Centric Knowledge Graph
# ============================================

class RiskLevel(str, Enum):
    SAFE = "SAFE"               # ç¬¦åˆå®˜æ–¹å™äº‹
    CONTROVERSIAL = "CONTROVERSIAL"  # æœ‰äº‰è®®/æœªå®šè®º
    HIGH_RISK = "HIGH_RISK"     # æ˜æ˜¾è¿è§„/å†å²è™šæ— ä¸»ä¹‰

class EntityType(str, Enum):
    PERSON = "PERSON"           # æ”¿æ²»äººç‰©
    LOCATION = "LOCATION"       # åœ°ç‚¹
    ORG = "ORG"                  # ç»„ç»‡/å…šæ´¾
    DOCUMENT = "DOCUMENT"       # æ–‡ä»¶/è‘—ä½œ/å†³è®®
    CONCEPT = "CONCEPT"         # ææ³•/å£å·/ä¸»ä¹‰

class EventType(str, Enum):
    MEETING = "MEETING"         # ä¼šè®®
    CONFLICT = "CONFLICT"       # æˆ˜äº‰/å†²çª
    SPEECH = "SPEECH"           # è®²è¯/å‘è¡¨
    POLICY = "POLICY"           # æ”¿ç­–å‡ºå°
    MOVEMENT = "MOVEMENT"       # æ”¿æ²»è¿åŠ¨

# ç§»é™¤ RelationType æšä¸¾ï¼Œæ”¹ä¸ºè‡ªç”±æ–‡æœ¬å…³ç³»

class EntityNode(BaseModel):
    """å®ä½“èŠ‚ç‚¹"""
    id: str = Field(..., description="å½’ä¸€åŒ–IDï¼Œå¦‚ 'PER_Mao_Zedong'")
    name: str = Field(..., description="å®ä½“æ ‡å‡†ä¸­æ–‡å")
    type: EntityType
    alias: List[str] = Field(default=[], description="æ–‡ä¸­å‡ºç°çš„åˆ«å/é»‘è¯")

class EventNode(BaseModel):
    """äº‹ä»¶èŠ‚ç‚¹"""
    id: str = Field(..., description="äº‹ä»¶IDï¼Œæ ¼å¼ï¼šEVT_åŠ¨è¯_ä¸»ä½“_æ—¶é—´")
    name: str = Field(..., description="äº‹ä»¶ç®€è¿°ï¼Œå¦‚'éµä¹‰ä¼šè®®å¬å¼€'")
    type: EventType
    time_str: str = Field(..., description="æ ‡å‡†åŒ–æ—¶é—´å­—ç¬¦ä¸² YYYY-MM-DD")
    description: str = Field(..., description="äº‹ä»¶çš„è¯¦ç»†ç»è¿‡æè¿°")
    political_significance: str = Field(..., description="è¯¥äº‹ä»¶çš„æ”¿æ²»å®šæ€§/å†å²æ„ä¹‰")
    risk_level: RiskLevel = Field(..., description="æ ¹æ®è¾“å…¥æºåˆ¤æ–­è¯¥æè¿°çš„é£é™©ç­‰çº§")

class RelationEdge(BaseModel):
    """å…³ç³»è¾¹"""
    source_id: str = Field(..., description="æºèŠ‚ç‚¹ID (Entity æˆ– Event)")
    target_id: str = Field(..., description="ç›®æ ‡èŠ‚ç‚¹ID")
    relation: str = Field(..., description="å…³ç³»åŠ¨è¯/åŠ¨ä½œï¼Œå¦‚ï¼šå‚ä¸ã€ç»„ç»‡ã€å‘èµ·ã€æ‰¹è¯„ã€æ”¯æŒã€åå¯¹ã€ä»»å‘½ã€å‡ºå¸­ã€é¢†å¯¼ã€æå‡ºã€æ‰¹å‡†ã€ç­¾ç½²ã€è°ƒä»»ã€é€®æ•ã€å¤„å†³ã€å¹³åç­‰")
    details: str = Field(..., description="å…³ç³»çš„å…·ä½“ç»†èŠ‚ï¼Œå¦‚'æ‹…ä»»ç»„é•¿'ã€'é€ æˆ300äººä¼¤äº¡'")
    evidence: str = Field(..., description="åŸæ–‡è¯æ®ç‰‡æ®µ")

class HistoricalGraphBatch(BaseModel):
    """å•æ¬¡å¤„ç†è¿”å›çš„å›¾è°±åˆ‡ç‰‡"""
    entities: List[EntityNode]
    events: List[EventNode]
    relations: List[RelationEdge]

ENTITY_TYPE_CN = {
    "PERSON": "äººç‰©", "LOCATION": "åœ°ç‚¹", "ORG": "ç»„ç»‡",
    "DOCUMENT": "æ–‡ä»¶", "CONCEPT": "æ¦‚å¿µ"
}

EVENT_TYPE_CN = {
    "MEETING": "ä¼šè®®", "CONFLICT": "å†²çª", "SPEECH": "è®²è¯",
    "POLICY": "æ”¿ç­–", "MOVEMENT": "è¿åŠ¨"
}

RISK_LEVEL_CN = {
    "SAFE": "ç¬¦åˆå®˜æ–¹å™äº‹", "CONTROVERSIAL": "æœ‰äº‰è®®/æœªå®šè®º", "HIGH_RISK": "æ˜æ˜¾è¿è§„"
}

RELATION_TYPE_CN = {
    "PARTICIPATED_IN": "å‚ä¸", "ORGANIZED": "ç»„ç»‡", "OCCURRED_AT": "å‘ç”Ÿäº",
    "CAUSED": "å¯¼è‡´", "CONTRADICTS": "é©³æ–¥", "DEFINED_AS": "å®šæ€§ä¸º"
}

# ============================================
# Session State
# ============================================
if "step" not in st.session_state:
    st.session_state.step = 1
if "text_content" not in st.session_state:
    st.session_state.text_content = ""
if "chunks" not in st.session_state:
    st.session_state.chunks = []
if "entities" not in st.session_state:
    st.session_state.entities = []
if "events" not in st.session_state:
    st.session_state.events = []
if "relations" not in st.session_state:
    st.session_state.relations = []
if "focus_stats" not in st.session_state:
    st.session_state.focus_stats = {"nodes": 0, "relations": 0}

CHUNK_SIZE = 4000

# ============================================
# File Reading
# ============================================
def read_file(f):
    name = getattr(f, "name", "")
    ext = name.lower().rsplit(".", 1)[-1] if "." in name else ""
    data = f.read()
    if hasattr(f, "seek"):
        f.seek(0)
    
    text = ""
    try:
        if ext == "pdf":
            for page in pypdf.PdfReader(io.BytesIO(data)).pages:
                text += (page.extract_text() or "") + "\n"
        elif ext == "epub":
            with tempfile.NamedTemporaryFile(delete=False, suffix=".epub") as tmp:
                tmp.write(data)
                path = tmp.name
            try:
                book = epub.read_epub(path, options={'ignore_ncx': True})
                for item in book.get_items():
                    if item.get_type() == ebooklib.ITEM_DOCUMENT:
                        soup = BeautifulSoup(item.get_content(), "html.parser")
                        for tag in soup(['script', 'style']):
                            tag.decompose()
                        text += soup.get_text(separator='\n', strip=True) + "\n"
            finally:
                if os.path.exists(path):
                    os.remove(path)
        elif ext in ["docx", "doc"]:
            text = "\n".join(p.text for p in Document(io.BytesIO(data)).paragraphs)
        else:
            text = data.decode("utf-8", errors="ignore")
    except Exception as e:
        st.error(f"è¯»å–å¤±è´¥: {e}")
    return re.sub(r'\n{3,}', '\n\n', text).strip()

def split_text_simple(text, size=CHUNK_SIZE):
    """ç®€å•åˆ‡åˆ†ï¼ˆå¤‡ç”¨ï¼‰"""
    paragraphs = re.split(r'\n\s*\n', text)
    chunks, current = [], ""
    for p in paragraphs:
        p = p.strip()
        if not p:
            continue
        if len(current) + len(p) < size:
            current += "\n\n" + p if current else p
        else:
            if current:
                chunks.append(current)
            current = p
    if current:
        chunks.append(current)
    return chunks or [text[:size]]

# ============================================
# LLM Client
# ============================================
@st.cache_resource
def get_client(key):
    return genai.Client(api_key=key)

# ============================================
# äº‹ä»¶åˆ‡åˆ†å…³é”®è¯ï¼ˆè§„åˆ™ä¼˜å…ˆ + å°‘é‡ LLM æ ¡éªŒï¼‰
# ============================================
EVENT_BREAK_KEYWORDS = [
    # æ—¶é—´è·³è·ƒ
    "ç¬¬äºŒå¤©", "æ¬¡æ—¥", "ç¿Œæ—¥", "å‡ å¤©å", "æ•°æ—¥å", "ä¸€å‘¨å", "å‡ å‘¨å",
    "ä¸€ä¸ªæœˆå", "æ•°æœˆå", "åŠå¹´å", "ä¸€å¹´å", "å¤šå¹´å", "è‹¥å¹²å¹´å",
    "è½¬çœ¼", "ä¸ä¹…", "éšå", "æ­¤å", "åæ¥", "æœ€ç»ˆ", "ç»ˆäº",
    # ç©ºé—´è·³è·ƒ
    "ä¸æ­¤åŒæ—¶", "å¦ä¸€è¾¹", "åœ¨å¦ä¸€å¤„", "åœ¨åŒ—äº¬", "åœ¨ä¸Šæµ·", "åœ¨å»¶å®‰",
    "å›åˆ°", "æ¥åˆ°", "æŠµè¾¾", "å‰å¾€", "ç¦»å¼€",
    # æ–°äº‹ä»¶æ ‡å¿—
    "ä¼šè®®å¼€å§‹", "ä¼šè®®å¬å¼€", "å¤§ä¼šå¼€å¹•", "ä¼šä¸Š", "ä¼šå",
    "æˆ˜æ–—æ‰“å“", "æˆ˜å½¹å¼€å§‹", "å†²çªçˆ†å‘",
    "å‘è¡¨è®²è¯", "ä½œæŠ¥å‘Š", "å‘è¨€æŒ‡å‡º", "å®£å¸ƒ",
    "é¢å¸ƒ", "å‡ºå°", "é€šè¿‡å†³è®®", "ç­¾ç½²",
    # ç« èŠ‚æ ‡è®°
    "ç¬¬ä¸€ç« ", "ç¬¬äºŒç« ", "ç¬¬ä¸‰ç« ", "ç¬¬å››ç« ", "ç¬¬äº”ç« ",
    "ä¸€ã€", "äºŒã€", "ä¸‰ã€", "å››ã€", "äº”ã€",
    "ï¼ˆä¸€ï¼‰", "ï¼ˆäºŒï¼‰", "ï¼ˆä¸‰ï¼‰", "ï¼ˆå››ï¼‰", "ï¼ˆäº”ï¼‰",
]

BREAKPOINT_PROMPT = """åˆ¤æ–­ä»¥ä¸‹ä¸¤ä¸ªæ®µè½ä¹‹é—´æ˜¯å¦å‘ç”Ÿäº†ã€æ˜æ˜¾çš„äº‹ä»¶è½¬ç§»ã€‘æˆ–ã€æ—¶é—´/åœ°ç‚¹çš„å¤§å¹…è·³è·ƒã€‘ã€‚

ä¸Šä¸€æ®µçš„ç»“å°¾: "...{prev_end}"
ä¸‹ä¸€æ®µçš„å¼€å¤´: "{next_start}..."

å¦‚æœæ˜¯åŒä¸€ä¸ªäº‹ä»¶çš„å»¶ç»­ï¼Œè¾“å‡º NOã€‚
å¦‚æœæ˜¯æ–°çš„äº‹ä»¶å¼€å§‹ï¼Œè¾“å‡º YESã€‚
åªè¾“å‡º YES æˆ– NOã€‚"""

def is_obvious_break(para_start: str) -> bool:
    """è§„åˆ™åˆ¤æ–­ï¼šæ˜¯å¦ä¸ºæ˜æ˜¾çš„äº‹ä»¶æ–­ç‚¹"""
    for kw in EVENT_BREAK_KEYWORDS:
        if kw in para_start[:50]:
            return True
    return False

def fast_event_chunker(
    book_content: str, 
    min_chunk_size: int = 800,
    max_chunk_size: int = 3000
) -> List[str]:
    """
    å¿«é€Ÿåˆ‡åˆ†ï¼šçº¯è§„åˆ™ï¼Œæ—  LLM è°ƒç”¨
    """
    paragraphs = [p.strip() for p in book_content.split('\n') if p.strip()]
    if len(paragraphs) == 0:
        return [book_content[:max_chunk_size]] if book_content else []
    
    chunks, current_buffer, current_len = [], [], 0

    for para in paragraphs:
        para_len = len(para)
        if not current_buffer:
            current_buffer.append(para)
            current_len += para_len
            continue
        if current_len < min_chunk_size:
            current_buffer.append(para)
            current_len += para_len
            continue
        if current_len + para_len > max_chunk_size:
            chunks.append("\n".join(current_buffer))
            current_buffer = [para]
            current_len = para_len
            continue
        if is_obvious_break(para):
            chunks.append("\n".join(current_buffer))
            current_buffer = [para]
            current_len = para_len
        else:
            current_buffer.append(para)
            current_len += para_len

    if current_buffer:
        chunks.append("\n".join(current_buffer))

    return chunks


def smart_event_chunker_hybrid(
    book_content: str,
    client,
    model: str,
    min_chunk_size: int = 700,
    max_chunk_size: int = 3400,
    llm_budget: int = 35
) -> List[str]:
    """
    æ··åˆåˆ‡åˆ†ï¼šè§„åˆ™ä¸ºä¸»ï¼Œå°‘é‡ LLM æ ¡éªŒ
    - è§„åˆ™å‘½ä¸­ç›´æ¥åˆ‡åˆ†
    - ä»…åœ¨â€œä¸æ˜æ˜¾â€åœºæ™¯ä½¿ç”¨ LLMï¼Œä¸”æœ‰è°ƒç”¨ä¸Šé™
    """
    paragraphs = [p.strip() for p in book_content.split('\n') if p.strip()]
    if len(paragraphs) == 0:
        return [book_content[:max_chunk_size]] if book_content else []

    chunks, current_buffer, current_len = [], [], 0

    for para in paragraphs:
        para_len = len(para)
        if not current_buffer:
            current_buffer.append(para)
            current_len += para_len
            continue
        if current_len < min_chunk_size:
            current_buffer.append(para)
            current_len += para_len
            continue
        if current_len + para_len > max_chunk_size:
            chunks.append("\n".join(current_buffer))
            current_buffer = [para]
            current_len = para_len
            continue
        if is_obvious_break(para):
            chunks.append("\n".join(current_buffer))
            current_buffer = [para]
            current_len = para_len
            continue

        decision = "NO"
        if llm_budget > 0:
            prev_end = current_buffer[-1][-60:]
            next_start = para[:60]
            try:
                response = client.models.generate_content(
                    model=model,
                    contents=BREAKPOINT_PROMPT.format(prev_end=prev_end, next_start=next_start),
                    config=types.GenerateContentConfig(
                        max_output_tokens=3,
                        temperature=0.0
                    )
                )
                decision = response.text.strip().upper()
            except Exception:
                decision = "NO"
            llm_budget -= 1

        if "YES" in decision:
            chunks.append("\n".join(current_buffer))
            current_buffer = [para]
            current_len = para_len
        else:
            current_buffer.append(para)
            current_len += para_len

    if current_buffer:
        chunks.append("\n".join(current_buffer))

    return chunks

# ============================================
# Extraction with Structured Output + Context Injection
# ============================================
EXTRACTION_PROMPT_WITH_CONTEXT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†å²æ”¿æ²»æ–‡çŒ®åˆ†æä¸“å®¶ã€‚è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å®ä½“ã€äº‹ä»¶å’Œå…³ç³»ã€‚

ã€å…¨å±€èƒŒæ™¯ã€‘: {global_context}
ã€å‰æƒ…æè¦ã€‘: {last_event_summary}

ã€å½“å‰æ–‡æœ¬ã€‘:
{text}

**æå–è¦æ±‚ï¼š**
1. **å®ä½“ (entities)**ï¼šæ”¿æ²»äººç‰©ã€åœ°ç‚¹ã€ç»„ç»‡ã€æ–‡ä»¶/è‘—ä½œã€æ¦‚å¿µ/ææ³•
2. **äº‹ä»¶ (events)**ï¼šä¼šè®®ã€å†²çªã€è®²è¯ã€æ”¿ç­–å‡ºå°ã€æ”¿æ²»è¿åŠ¨  
3. **å…³ç³» (relations)**ï¼šå®ä½“ä¸äº‹ä»¶ä¹‹é—´çš„æ‰€æœ‰å…³ç³»ï¼Œç”¨å…·ä½“åŠ¨è¯æè¿°

**å…³ç³»åŠ¨è¯ç¤ºä¾‹ï¼ˆå°½é‡ä½¿ç”¨å…·ä½“åŠ¨è¯ï¼‰ï¼š**
- äºº-äº‹ä»¶ï¼šå‚ä¸ã€ä¸»æŒã€å‡ºå¸­ã€å‘èµ·ã€ç»„ç»‡ã€é¢†å¯¼ã€ç­–åˆ’ã€åå¯¹ã€æ”¯æŒã€æ‰¹è¯„
- äºº-äººï¼šä»»å‘½ã€ææ‹”ã€æ‰¹è¯„ã€æ”¯æŒã€åå¯¹ã€é€®æ•ã€å¤„å†³ã€å¹³åã€ä¼šè§ã€æŒ‡ç¤º
- äºº-ç»„ç»‡ï¼šåŠ å…¥ã€é¢†å¯¼ã€åˆ›å»ºã€é€€å‡ºã€æ”¹ç»„ã€æ‹…ä»»
- äºº-åœ°ç‚¹ï¼šå‰å¾€ã€è§†å¯Ÿã€é©»å®ˆã€æ’¤ç¦»ã€æŠµè¾¾
- äº‹ä»¶-äº‹ä»¶ï¼šå¯¼è‡´ã€å¼•å‘ã€ä¿ƒæˆã€ä¸­æ–­ã€å»¶ç»­
- å…¶ä»–ï¼šç­¾ç½²ã€æ‰¹å‡†ã€æå‡ºã€å‘è¡¨ã€å®£å¸ƒã€é¢å¸ƒã€ä¿®è®¢ã€åºŸé™¤

**é£é™©ç­‰çº§åˆ¤æ–­æ ‡å‡†ï¼š**
- SAFE: ç¬¦åˆå®˜æ–¹å†å²å™äº‹
- CONTROVERSIAL: å­˜åœ¨äº‰è®®æˆ–æœªå®šè®º
- HIGH_RISK: æ˜æ˜¾è¿èƒŒå®˜æ–¹å™äº‹ã€å†å²è™šæ— ä¸»ä¹‰å€¾å‘

**IDè§„èŒƒï¼š**
- å®ä½“ID: PER_å§“å / LOC_åœ°å / ORG_ç»„ç»‡å / DOC_æ–‡ä»¶å / CON_æ¦‚å¿µå
- äº‹ä»¶ID: EVT_äº‹ä»¶ç®€ç§°_å¹´ä»½

**é‡è¦ï¼šå®å¯å¤šæå–ä¹Ÿä¸è¦é—æ¼ï¼æ¯ä¸ªå®ä½“è‡³å°‘è¦æœ‰ä¸€æ¡å…³ç³»ã€‚**

è¯·æå–æ‰€æœ‰å®ä½“ã€äº‹ä»¶å’Œå®ƒä»¬ä¹‹é—´çš„å…³ç³»ï¼Œæ³¨æ„ä¿æŒä¸å‰æ–‡çš„IDä¸€è‡´æ€§ã€‚"""

def extract_with_context(
    client, 
    model: str, 
    text: str,
    global_context: str = "",
    last_event_summary: str = "æ— "
) -> HistoricalGraphBatch:
    """ä½¿ç”¨ Pydantic Schema è¿›è¡Œç»“æ„åŒ–æŠ½å–ï¼ˆå¸¦ä¸Šä¸‹æ–‡ï¼‰"""
    try:
        prompt = EXTRACTION_PROMPT_WITH_CONTEXT.format(
            global_context=global_context or "å†å²æ”¿æ²»æ–‡çŒ®åˆ†æ",
            last_event_summary=last_event_summary,
            text=text
        )
        response = client.models.generate_content(
            model=model,
            contents=prompt,
            config=types.GenerateContentConfig(
                response_mime_type="application/json",
                response_schema=HistoricalGraphBatch
            )
        )
        data = json.loads(response.text)
        return HistoricalGraphBatch(**data)
    except Exception as e:
        st.warning(f"æŠ½å–è­¦å‘Š: {e}")
        return HistoricalGraphBatch(entities=[], events=[], relations=[])


from concurrent.futures import ThreadPoolExecutor, as_completed

def process_book_pipeline(
    book_text: str,
    client,
    model: str,
    global_context: str = "",
    chunk_mode: str = "hybrid",
    llm_budget: int = 35,
    max_workers: int = 5
) -> List[HistoricalGraphBatch]:
    """
    ä¸Šä¸‹æ–‡æ³¨å…¥å‡½æ•°ï¼ˆå¹¶è¡Œä¼˜åŒ–ç‰ˆï¼‰ï¼š
    1) äº‹ä»¶åˆ‡åˆ†ï¼ˆæ··åˆ/çº¯è§„åˆ™/å›ºå®šé•¿åº¦ï¼‰
    2) å¹¶è¡ŒæŠ½å–å„å—
    3) è¿”å›æ¯å—çš„ç»“æ„åŒ–å›¾è°±
    """
    # å¤§æ–‡ä»¶ç”¨æ›´å¤§çš„ chunk å‡å°‘è°ƒç”¨æ¬¡æ•°
    text_len = len(book_text)
    if text_len > 500000:  # > 500KB
        min_size, max_size = 2000, 6000
    elif text_len > 100000:  # > 100KB
        min_size, max_size = 1200, 4500
    else:
        min_size, max_size = 700, 3400
    
    if chunk_mode == "hybrid":
        raw_chunks = smart_event_chunker_hybrid(
            book_text, client, model,
            min_chunk_size=min_size,
            max_chunk_size=max_size,
            llm_budget=llm_budget
        )
    elif chunk_mode == "fixed":
        raw_chunks = split_text_simple(book_text, size=max_size)
    else:
        raw_chunks = fast_event_chunker(book_text, min_chunk_size=min_size, max_chunk_size=max_size)

    total_chunks = len(raw_chunks)
    
    # å¹¶è¡ŒæŠ½å–ï¼ˆå¸¦è¿›åº¦æ¡ï¼‰
    all_graph_data = [None] * total_chunks
    completed = [0]  # ç”¨åˆ—è¡¨ä»¥ä¾¿åœ¨é—­åŒ…ä¸­ä¿®æ”¹
    
    progress_bar = st.progress(0, text=f"æŠ½å–è¿›åº¦: 0/{total_chunks}")
    
    def extract_chunk(idx, chunk):
        return idx, extract_with_context(
            client, model, chunk,
            global_context=global_context,
            last_event_summary="æ— "  # å¹¶è¡Œæ—¶æ— æ³•ä¸²è¡Œä¼ é€’ä¸Šä¸‹æ–‡
        )
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [executor.submit(extract_chunk, i, c) for i, c in enumerate(raw_chunks)]
        for future in as_completed(futures):
            idx, result = future.result()
            all_graph_data[idx] = result
            completed[0] += 1
            progress_bar.progress(
                completed[0] / total_chunks, 
                text=f"æŠ½å–è¿›åº¦: {completed[0]}/{total_chunks}"
            )
    
    progress_bar.empty()
    return [g for g in all_graph_data if g is not None]


def aggregate_graph_batches(batches: List[HistoricalGraphBatch]):
    """åˆå¹¶å¤šä¸ªæ‰¹æ¬¡çš„å›¾è°±æ•°æ®ï¼ˆå»é‡ï¼‰"""
    all_entities = {}
    all_events = {}
    all_relations = []

    for batch in batches:
        for e in batch.entities:
            if e.id not in all_entities:
                all_entities[e.id] = e.model_dump()
        for ev in batch.events:
            if ev.id not in all_events:
                all_events[ev.id] = ev.model_dump()
        for r in batch.relations:
            all_relations.append(r.model_dump())

    seen = set()
    unique_relations = []
    for r in all_relations:
        key = f"{r['source_id']}|{r['relation']}|{r['target_id']}"
        if key not in seen:
            seen.add(key)
            unique_relations.append(r)

    return list(all_entities.values()), list(all_events.values()), unique_relations


def find_orphan_nodes(entities, events, relations):
    """æ‰¾å‡ºæ²¡æœ‰ä»»ä½•å…³ç³»çš„å­¤ç«‹èŠ‚ç‚¹"""
    connected_ids = set()
    for r in relations:
        connected_ids.add(r.get('source_id', ''))
        connected_ids.add(r.get('target_id', ''))
    
    orphan_entities = [e for e in entities if e['id'] not in connected_ids]
    orphan_events = [e for e in events if e['id'] not in connected_ids]
    return orphan_entities, orphan_events


def integrate_orphans(client, model, orphan_entities, orphan_events, all_entities, all_events):
    """ä¸ºå­¤ç«‹èŠ‚ç‚¹æ¨æ–­å…³ç³»ï¼ˆåŸºäºå·²æœ‰å›¾è°±ä¸Šä¸‹æ–‡ï¼‰"""
    if not orphan_entities and not orphan_events:
        return []
    
    # æ„å»ºä¸Šä¸‹æ–‡ï¼šå·²æœ‰çš„å®ä½“å’Œäº‹ä»¶
    context_entities = [f"{e['id']}: {e['name']}" for e in all_entities[:50]]
    context_events = [f"{e['id']}: {e['name']} ({e.get('time_str', '')})" for e in all_events[:30]]
    
    orphan_list = []
    for e in orphan_entities:
        orphan_list.append(f"å®ä½“ {e['id']}: {e['name']} (ç±»å‹: {e['type']})")
    for e in orphan_events:
        orphan_list.append(f"äº‹ä»¶ {e['id']}: {e['name']} ({e.get('time_str', '')})")
    
    if not orphan_list:
        return []
    
    prompt = f"""ä»¥ä¸‹æ˜¯ä¸€ä¸ªå†å²çŸ¥è¯†å›¾è°±ä¸­çš„å­¤ç«‹èŠ‚ç‚¹ï¼ˆæ²¡æœ‰ä¸å…¶ä»–èŠ‚ç‚¹å»ºç«‹å…³ç³»ï¼‰ã€‚
è¯·æ ¹æ®ä½ å¯¹ä¸­å›½å†å²çš„äº†è§£ï¼Œä¸ºè¿™äº›å­¤ç«‹èŠ‚ç‚¹æ¨æ–­åˆç†çš„å…³ç³»ã€‚

ã€å·²æœ‰å®ä½“ã€‘:
{chr(10).join(context_entities)}

ã€å·²æœ‰äº‹ä»¶ã€‘:
{chr(10).join(context_events)}

ã€å­¤ç«‹èŠ‚ç‚¹ã€‘:
{chr(10).join(orphan_list)}

è¯·ä¸ºæ¯ä¸ªå­¤ç«‹èŠ‚ç‚¹ç”Ÿæˆ1-3æ¡ä¸å·²æœ‰èŠ‚ç‚¹çš„å…³ç³»ã€‚å…³ç³»å¿…é¡»ç¬¦åˆå†å²äº‹å®ã€‚
å¦‚æœæ— æ³•ç¡®å®šå…³ç³»ï¼Œå¯ä»¥è·³è¿‡è¯¥èŠ‚ç‚¹ã€‚

è¿”å›JSONæ ¼å¼ï¼š
{{"relations": [
  {{"source_id": "...", "target_id": "...", "relation": "åŠ¨è¯", "details": "å…·ä½“è¯´æ˜", "evidence": "åŸºäºå†å²å¸¸è¯†"}}
]}}
"""
    
    try:
        response = client.models.generate_content(
            model=model,
            contents=prompt,
            config=types.GenerateContentConfig(
                response_mime_type="application/json"
            )
        )
        data = json.loads(response.text)
        return data.get('relations', [])
    except Exception as e:
        st.warning(f"å­¤ç«‹èŠ‚ç‚¹æ•´åˆå¤±è´¥: {e}")
        return []


# ============================================
# å…³æ³¨åº¦è¯„ä¼°ä¸å…³ç³»è¿‡æ»¤ï¼ˆäº‹ä»¶ä¸­å¿ƒï¼‰
# ============================================
FOCUS_KEYWORDS_STRONG = [
    "æ€»ä¹¦è®°", "ä¸»å¸­", "å†›å§”ä¸»å¸­", "æ€»ç†", "æ€»å¸ä»¤",
    "ä¸­å¤®å†›å§”", "å†›å§”", "æ”¿æ²»å±€", "å¸¸å§”", "ä¸­å¤®å§”å‘˜ä¼š",
    "å›½åŠ¡é™¢", "å›½å®¶å®‰å…¨", "å…¬å®‰", "å›½å®‰", "æ­¦è­¦",
    "è§£æ”¾å†›", "æˆ˜åŒº", "å†›åŒº", "æµ·å†›", "ç©ºå†›", "ç«ç®­å†›",
    "å›½é˜²éƒ¨", "å¤–äº¤éƒ¨", "ä¸­å®£éƒ¨", "ä¸­ç»„éƒ¨", "äººå¤§", "æ”¿å"
]
FOCUS_KEYWORDS_MID = [
    "å…š", "æ”¿åºœ", "å†›", "å†›é˜Ÿ", "éƒ¨é˜Ÿ", "å§”å‘˜ä¼š", "å…šå§”", "çœå§”", "å¸‚å§”",
    "æŒ‡æŒ¥éƒ¨", "å¸ä»¤éƒ¨", "æ€»å‚", "æ€»å", "æ€»æ”¿"
]

EVENT_IMPORTANCE_BASE = {
    "MEETING": 5, "POLICY": 5, "MOVEMENT": 5,
    "CONFLICT": 4, "SPEECH": 4
}

REL_BONUS = {
    "ORGANIZED": 2,
    "DEFINED_AS": 2,
    "CAUSED": 2,
    "PARTICIPATED_IN": 1
}

RISK_BONUS = {"SAFE": 1, "CONTROVERSIAL": 2, "HIGH_RISK": 3}


def _contains_any(text: str, keywords: List[str]) -> bool:
    return any(k and (k in text) for k in keywords)


def compute_entity_importance(e: dict, extra_focus: Optional[List[str]] = None) -> int:
    name = e.get("name", "")
    etype = e.get("type", "")
    base = {"PERSON": 5, "ORG": 4, "DOCUMENT": 3, "CONCEPT": 3, "LOCATION": 2}.get(etype, 2)
    score = base

    if _contains_any(name, FOCUS_KEYWORDS_STRONG):
        score += 4
    if _contains_any(name, FOCUS_KEYWORDS_MID):
        score += 2
    if extra_focus and _contains_any(name, extra_focus):
        score += 3

    return min(score, 10)


def compute_event_importance(ev: dict, extra_focus: Optional[List[str]] = None) -> int:
    base = EVENT_IMPORTANCE_BASE.get(ev.get("type", ""), 3)
    text = f"{ev.get('name','')} {ev.get('political_significance','')}"
    score = base

    if _contains_any(text, FOCUS_KEYWORDS_STRONG):
        score += 3
    if _contains_any(text, FOCUS_KEYWORDS_MID):
        score += 1
    if extra_focus and _contains_any(text, extra_focus):
        score += 2

    score += RISK_BONUS.get(ev.get("risk_level", "SAFE"), 1)
    return min(score, 10)


def prioritize_graph(entities, events, relations, min_weight=5, top_per_event=8, extra_focus: Optional[List[str]] = None):
    entity_score = {e["id"]: compute_entity_importance(e, extra_focus=extra_focus) for e in entities}
    event_score = {ev["id"]: compute_event_importance(ev, extra_focus=extra_focus) for ev in events}

    filtered = []
    event_relations = defaultdict(list)

    for r in relations:
        src, tgt = r.get("source_id"), r.get("target_id")
        if src in event_score or tgt in event_score:
            src_score = event_score.get(src, entity_score.get(src, 2))
            tgt_score = event_score.get(tgt, entity_score.get(tgt, 2))
            rel_bonus = REL_BONUS.get(r.get("relation"), 0)
            weight = min(int((src_score + tgt_score) / 2 + rel_bonus), 10)
            r["weight"] = weight
            filtered.append(r)
            event_id = src if src in event_score else tgt
            event_relations[event_id].append(r)

    keep = set()
    for event_id, rels in event_relations.items():
        rels_sorted = sorted(rels, key=lambda x: x.get("weight", 0), reverse=True)
        for r in rels_sorted[:top_per_event]:
            keep.add(f"{r['source_id']}|{r['relation']}|{r['target_id']}")
        for r in rels_sorted:
            if r.get("weight", 0) >= min_weight:
                keep.add(f"{r['source_id']}|{r['relation']}|{r['target_id']}")

    final_relations = []
    for r in filtered:
        key = f"{r['source_id']}|{r['relation']}|{r['target_id']}"
        if key in keep:
            final_relations.append(r)

    focus_nodes = sum(1 for s in list(entity_score.values()) + list(event_score.values()) if s >= 7)
    focus_relations = sum(1 for r in final_relations if r.get("weight", 0) >= 7)

    return entities, events, final_relations, {"nodes": focus_nodes, "relations": focus_relations}


# é«˜å±å…³é”®è¯ï¼ˆä¸å½’å…¥æ•£ç‚¹å®¹å™¨ï¼‰
HIGH_RISK_KEYWORDS = [
    "æ¸…æ´—", "è‚ƒå", "æ•´é£", "æ‰¹æ–—", "è¿«å®³", "å†¤æ¡ˆ", "å¹³å", "å¤„å†³", "æªå†³",
    "ä¸‘é—»", "è…è´¥", "è´ªæ±¡", "å—è´¿", "åŒè§„", "è½é©¬", "è°ƒæŸ¥", "å®¡æŸ¥",
    "æ”¿å˜", "å…µå˜", "å›é€ƒ", "æš—æ€", "é‡åˆº", "è‡ªæ€", "éæ­£å¸¸æ­»äº¡",
    "å…­å››", "å¤©å®‰é—¨", "åå³", "æ–‡é©", "å¤§è·ƒè¿›", "ä¸‰å¹´å›°éš¾",
    "æ—å½ª", "å››äººå¸®", "æ±Ÿé’", "åº·ç”Ÿ", "å‘¨æ°¸åº·", "è–„ç†™æ¥", "ä»¤è®¡åˆ’", "å¾æ‰åš", "éƒ­ä¼¯é›„"
]


def is_high_risk_node(node):
    """åˆ¤æ–­èŠ‚ç‚¹æ˜¯å¦æ¶‰åŠé«˜å±å†…å®¹"""
    # æ£€æŸ¥äº‹ä»¶é£é™©ç­‰çº§
    if node.get("risk_level") in ("HIGH_RISK", "CONTROVERSIAL"):
        return True
    
    # æ£€æŸ¥åç§°å’Œæè¿°æ˜¯å¦åŒ…å«é«˜å±å…³é”®è¯
    text = f"{node.get('name', '')} {node.get('description', '')} {node.get('political_significance', '')}"
    for kw in HIGH_RISK_KEYWORDS:
        if kw in text:
            return True
    return False


def find_sparse_nodes(entities, events, relations, max_relations=2):
    """æ‰¾å‡ºå…³ç³»ç¨€ç–çš„èŠ‚ç‚¹"""
    node_relation_count = defaultdict(int)
    for r in relations:
        node_relation_count[r.get("source_id", "")] += 1
        node_relation_count[r.get("target_id", "")] += 1
    
    sparse_entities = [e for e in entities if node_relation_count.get(e["id"], 0) <= max_relations]
    sparse_events = [ev for ev in events if node_relation_count.get(ev["id"], 0) <= max_relations]
    main_entities = [e for e in entities if node_relation_count.get(e["id"], 0) > max_relations]
    main_events = [ev for ev in events if node_relation_count.get(ev["id"], 0) > max_relations]
    
    return main_entities, main_events, sparse_entities, sparse_events


def integrate_sparse_with_search(client, model, sparse_entities, sparse_events, main_entities, main_events):
    """
    ç”¨ LLM + å¤–éƒ¨çŸ¥è¯†ä¸ºæ•£ç‚¹æ‰¾ä¸»å›¾å…³è”
    è¿”å›ï¼šæ–°å…³ç³»åˆ—è¡¨ï¼Œæœªæ•´åˆçš„èŠ‚ç‚¹åˆ—è¡¨
    """
    if not sparse_entities and not sparse_events:
        return [], [], []
    
    # æ„å»ºä¸»å›¾ä¸Šä¸‹æ–‡
    main_entity_names = [f"{e['id']}: {e['name']}" for e in main_entities[:40]]
    main_event_names = [f"{ev['id']}: {ev['name']} ({ev.get('time_str','')})" for ev in main_events[:30]]
    
    # æ•£ç‚¹åˆ—è¡¨
    sparse_list = []
    for e in sparse_entities:
        sparse_list.append({"id": e["id"], "name": e["name"], "type": e.get("type", ""), "is_event": False})
    for ev in sparse_events:
        sparse_list.append({"id": ev["id"], "name": ev["name"], "type": ev.get("type", ""), "time": ev.get("time_str", ""), "is_event": True})
    
    if not sparse_list:
        return [], [], []
    
    prompt = f"""ä½ æ˜¯ä¸­å›½è¿‘ç°ä»£å²ä¸“å®¶ã€‚ä»¥ä¸‹æ•£ç‚¹èŠ‚ç‚¹åœ¨çŸ¥è¯†å›¾è°±ä¸­å…³ç³»ç¨€ç–ï¼Œè¯·æ ¹æ®å†å²äº‹å®ä¸ºå®ƒä»¬æ‰¾åˆ°ä¸ä¸»å›¾èŠ‚ç‚¹çš„å…³è”ã€‚

ã€ä¸»å›¾å®ä½“ã€‘:
{chr(10).join(main_entity_names)}

ã€ä¸»å›¾äº‹ä»¶ã€‘:
{chr(10).join(main_event_names)}

ã€æ•£ç‚¹èŠ‚ç‚¹ã€‘:
{json.dumps(sparse_list, ensure_ascii=False, indent=2)}

**ä»»åŠ¡ï¼š**
1. æ ¹æ®ä½ å¯¹ä¸­å›½å†å²çš„äº†è§£ï¼Œä¸ºæ¯ä¸ªæ•£ç‚¹æ‰¾1-3æ¡ä¸ä¸»å›¾èŠ‚ç‚¹çš„çœŸå®å…³ç³»
2. å…³ç³»å¿…é¡»ç¬¦åˆå†å²äº‹å®ï¼Œä¸èƒ½ç¼–é€ 
3. å¦‚æœæŸä¸ªæ•£ç‚¹ç¡®å®ä¸ä¸»å›¾æ— å…³ï¼Œå°†å…¶æ ‡è®°ä¸º unlinked

**è¿”å›JSONæ ¼å¼ï¼š**
{{
  "new_relations": [
    {{"source_id": "æ•£ç‚¹ID", "target_id": "ä¸»å›¾èŠ‚ç‚¹ID", "relation": "åŠ¨è¯", "details": "è¯´æ˜", "evidence": "å†å²ä¾æ®"}}
  ],
  "unlinked_ids": ["æ— æ³•å…³è”çš„æ•£ç‚¹IDåˆ—è¡¨"]
}}
"""
    
    try:
        response = client.models.generate_content(
            model=model,
            contents=prompt,
            config=types.GenerateContentConfig(
                response_mime_type="application/json"
            )
        )
        data = json.loads(response.text)
        new_relations = data.get("new_relations", [])
        unlinked_ids = set(data.get("unlinked_ids", []))
        
        # åˆ†ç¦»å·²æ•´åˆå’Œæœªæ•´åˆçš„æ•£ç‚¹
        unlinked_entities = [e for e in sparse_entities if e["id"] in unlinked_ids]
        unlinked_events = [ev for ev in sparse_events if ev["id"] in unlinked_ids]
        
        return new_relations, unlinked_entities, unlinked_events
    except Exception as e:
        st.warning(f"æ•£ç‚¹æ•´åˆæ£€ç´¢å¤±è´¥: {e}")
        return [], sparse_entities, sparse_events


def build_sensitive_node(unlinked_entities, unlinked_events):
    """å°†æ— æ³•å…³è”çš„æ•£ç‚¹æ„å»ºä¸ºæ•æ„Ÿè¯åº“èŠ‚ç‚¹"""
    if not unlinked_entities and not unlinked_events:
        return None
    
    items = []
    for e in unlinked_entities:
        items.append(f"â€¢ {e['name']} ({ENTITY_TYPE_CN.get(e.get('type'), e.get('type'))})")
    for ev in unlinked_events:
        items.append(f"â—† {ev['name']} ({ev.get('time_str', '')})")
    
    return {
        "id": "_SENSITIVE_TERMS_",
        "label": f"æ•æ„Ÿè¯åº“ ({len(unlinked_entities) + len(unlinked_events)})",
        "items": items,
        "entities": unlinked_entities,
        "events": unlinked_events
    }


# ============================================
# Graph Building - Event-Centric
# ============================================
def build_event_graph(entities, events, relations, sensitive_node=None):
    """æ„å»ºä»¥äº‹ä»¶ä¸ºä¸­å¿ƒçš„å›¾è°±"""
    G = nx.DiGraph()
    
    # é¢œè‰²é…ç½® - å…šå²æ–‡çŒ®é£æ ¼
    entity_colors = {
        "PERSON": "#c62828", "LOCATION": "#1565c0", "ORG": "#2e7d32",
        "DOCUMENT": "#7b1fa2", "CONCEPT": "#f57c00"
    }
    
    event_colors = {
        "MEETING": "#1565c0", "CONFLICT": "#c62828", "SPEECH": "#2e7d32",
        "POLICY": "#7b1fa2", "MOVEMENT": "#f57c00"
    }
    
    risk_border = {
        "SAFE": "#2e7d32", "CONTROVERSIAL": "#f57c00", "HIGH_RISK": "#c62828"
    }
    
    # æ·»åŠ å®ä½“èŠ‚ç‚¹
    entity_map = {e["id"]: e for e in entities}
    for e in entities:
        G.add_node(
            e["id"],
            label=e["name"],
            color=entity_colors.get(e["type"], "#94a3b8"),
            size=20,
            shape="dot",
            title=f"{ENTITY_TYPE_CN.get(e['type'], e['type'])}: {e['name']}"
        )
    
    # æ·»åŠ äº‹ä»¶èŠ‚ç‚¹ï¼ˆæ›´å¤§ã€æ–¹å½¢è¡¨ç¤ºï¼‰
    event_map = {ev["id"]: ev for ev in events}
    for ev in events:
        risk = ev.get("risk_level", "SAFE")
        bg = event_colors.get(ev.get("type"), "#64748b")
        border = risk_border.get(risk, "#d1d5db")
        G.add_node(
            ev["id"],
            label=ev["name"],
            color={"background": bg, "border": border},
            size=38,
            shape="diamond",
            borderWidth=3,
            borderWidthSelected=5,
            title=(
                f"ã€{EVENT_TYPE_CN.get(ev.get('type'), ev.get('type'))}ã€‘{ev.get('name','')}\n"
                f"æ—¶é—´: {ev.get('time_str', 'æœªçŸ¥')}\n"
                f"é£é™©: {RISK_LEVEL_CN.get(risk, risk)}\n\n"
                f"{ev.get('description', '')}"
            )
        )
    
    # æ·»åŠ æ•æ„Ÿè¯åº“èŠ‚ç‚¹
    if sensitive_node:
        items = sensitive_node.get("items", [])
        G.add_node(
            sensitive_node["id"],
            label=sensitive_node["label"],
            color={"background": "#fef3c7", "border": "#f59e0b"},
            size=50,
            shape="box",
            borderWidth=3,
            font={"color": "#92400e", "size": 14, "bold": True},
            title="âš ï¸ æ•æ„Ÿè¯åº“ï¼ˆæ— æ³•å…³è”åˆ°ä¸»å›¾ï¼‰:\n\n" + "\n".join(items[:50]) + ("\n..." if len(items) > 50 else "")
        )
    
    # æ·»åŠ å…³ç³»è¾¹ï¼ˆä½¿ç”¨ç²¾é€‰æƒé‡ï¼Œå‡å°‘å†—ä½™ï¼‰
    for r in relations:
        src, tgt = r["source_id"], r["target_id"]
        if (src in entity_map or src in event_map) and (tgt in entity_map or tgt in event_map):
            w = int(r.get("weight", 5))
            edge_color = "#C41E3A" if w >= 7 else ("#666666" if w >= 5 else "#aaaaaa")
            G.add_edge(
                src, tgt,
                label=r.get("relation", ""),
                title=(r.get("details", "") + ("\n\nè¯æ®: " + r.get("evidence", "") if r.get("evidence") else "")),
                color=edge_color,
                width=1 + w / 3
            )
    
    return G

# ============================================
# Navigation Bar - å…šå²æ–‡çŒ®é£æ ¼ï¼ˆå±…ä¸­å¤§æ ‡é¢˜ï¼‰
# ============================================
st.markdown("""
<div class="dang-header">
    <div class="header-content">
        <span class="header-icon">â˜­</span>
        <span class="header-title">å…šæ”¿æ–‡çŒ®çŸ¥è¯†å›¾è°±ç”Ÿæˆ</span>
    </div>
    <div class="header-line">
        <div class="line-left"></div>
        <div class="line-center"></div>
        <div class="line-right"></div>
    </div>
</div>
<style>
    .dang-header {
        background: #ffffff;
        padding: 28px 0 0 0;
        text-align: center;
    }
    .header-content {
        display: flex;
        align-items: center;
        justify-content: center;
        gap: 16px;
    }
    .header-icon {
        font-size: 42px;
        color: #C9A227;
        line-height: 1;
        text-shadow: 1px 1px 2px rgba(0,0,0,0.15);
    }
    .header-title {
        font-family: "Noto Serif SC", "SimSun", "å®‹ä½“", serif;
        font-size: 36px;
        font-weight: 700;
        color: #C9A227;
        letter-spacing: 0.12em;
        text-shadow: 1px 1px 2px rgba(0,0,0,0.1);
    }
    .header-line {
        display: flex;
        align-items: center;
        justify-content: center;
        margin-top: 20px;
        padding: 0 60px;
    }
    .line-left, .line-right {
        flex: 1;
        height: 1px;
        background: #e5e5e5;
    }
    .line-center {
        width: 120px;
        height: 4px;
        background: #C41E3A;
        margin: 0 0;
    }
</style>
""", unsafe_allow_html=True)

# API Config
with st.container():
    col1, col2, col3, col4 = st.columns([1, 2, 2, 1])
    with col2:
        api_key = st.text_input("API Key", type="password", placeholder="Gemini API Key", label_visibility="collapsed")
    with col3:
        model = st.text_input("Model", value="gemini-3-flash-preview", placeholder="æ¨¡å‹åç§°", label_visibility="collapsed")

st.markdown("<br>", unsafe_allow_html=True)

# Step Navigation
def can_go(target):
    if target == 1:
        return True
    elif target == 2:
        return len(st.session_state.events) > 0
    elif target == 3:
        return len(st.session_state.relations) > 0
    return False

col1, col2, col3, col4, col5 = st.columns([2, 1, 1, 1, 2])

with col2:
    icon = "âœ“" if st.session_state.step > 1 else ("â—" if st.session_state.step == 1 else "â—‹")
    if st.button(f"{icon} ä¸Šä¼ ", key="nav1", use_container_width=True):
        st.session_state.step = 1
        st.rerun()

with col3:
    icon = "âœ“" if st.session_state.step > 2 else ("â—" if st.session_state.step == 2 else "â—‹")
    if st.button(f"{icon} å®¡æ ¸", key="nav2", use_container_width=True, disabled=not can_go(2)):
        st.session_state.step = 2
        st.rerun()

with col4:
    icon = "âœ“" if st.session_state.step > 3 else ("â—" if st.session_state.step == 3 else "â—‹")
    if st.button(f"{icon} å›¾è°±", key="nav3", use_container_width=True, disabled=not can_go(3)):
        st.session_state.step = 3
        st.rerun()

st.markdown("<hr style='border:none; border-top:1px solid #e5e5e5; margin:20px 0;'>", unsafe_allow_html=True)

# Sidebar
with st.sidebar:
    st.markdown("### ğŸ”§ å·¥å…·")
    if st.button("ğŸ”„ é‡æ–°å¼€å§‹", use_container_width=True):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()
    
    st.markdown("---")
    st.markdown("**ç»Ÿè®¡**")
    st.write(f"å®ä½“: {len(st.session_state.entities)}")
    st.write(f"äº‹ä»¶: {len(st.session_state.events)}")
    st.write(f"å…³ç³»: {len(st.session_state.relations)}")

# ============================================
# Step 1: Upload & Extract
# ============================================
if st.session_state.step == 1:
    st.markdown("""
    <div class="hero">
        <div class="hero-badge">æ™ºèƒ½æ–‡çŒ®è§£æç³»ç»Ÿ</div>
        <h1>è§£ä¹¦å®¢</h1>
        <h2>ä¸Šä¼ æ–‡æ¡£ï¼Œæ„å»ºå†å²äº‹ä»¶çŸ¥è¯†å›¾è°±</h2>
        <p class="hero-desc">åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½åˆ‡åˆ† Â· ä¸Šä¸‹æ–‡æ³¨å…¥æŠ½å– Â· å®ä½“å…³ç³»è¯†åˆ« Â· é£é™©è¯„ä¼°</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("<br>", unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        # å…¨å±€èƒŒæ™¯è¾“å…¥
        global_context = st.text_area(
            "å…¨å±€èƒŒæ™¯ï¼ˆå¯é€‰ï¼‰",
            placeholder="ç®€è¦æè¿°æ–‡æ¡£ä¸»é¢˜ï¼Œå¦‚ï¼šæœ¬ä¹¦è®²è¿°ä¸­å›½å…±äº§å…š1921-1949å¹´å‘å±•å†ç¨‹...",
            height=68,
            help="æä¾›èƒŒæ™¯æœ‰åŠ©äº LLM æ›´å‡†ç¡®åœ°æŠ½å–å†…å®¹"
        )
        
        # åˆ‡åˆ†æ¨¡å¼
        chunk_mode = st.radio(
            "åˆ‡åˆ†æ¨¡å¼",
            ["æ··åˆåˆ‡åˆ†ï¼ˆæ¨èï¼‰", "çº¯è§„åˆ™", "å›ºå®šé•¿åº¦"],
            horizontal=True,
            help="æ··åˆåˆ‡åˆ†ï¼šè§„åˆ™+å°‘é‡ LLM æ ¡éªŒï¼Œå…¼é¡¾å‡†ç¡®ä¸é€Ÿåº¦"
        )
        
        # Recall ä¼˜å…ˆï¼šé»˜è®¤ç»™æ›´é«˜çš„ LLM æ ¡éªŒé¢„ç®—ï¼Œé™ä½è¯¯åˆ‡å¯¼è‡´çš„æ¼æŠ½
        llm_budget = 35
        if "æ··åˆ" in chunk_mode:
            llm_budget = st.slider(
                "LLM æ–­ç‚¹æ ¡éªŒä¸Šé™",
                min_value=0,
                max_value=120,
                value=35,
                step=5,
                help="Recall ä¼˜å…ˆï¼šå€¼è¶Šå¤§è¶Šä¸å®¹æ˜“æ¼äº‹ä»¶ï¼ˆä½†ä¼šå˜æ…¢ï¼‰"
            )

        st.markdown("---")
        with st.expander("Advanced Settings", expanded=False):
            focus_extra_raw = st.text_input(
                "é¢å¤–å…³æ³¨å…³é”®è¯ï¼ˆå¯é€‰ï¼‰",
                placeholder="ç”¨é€—å·åˆ†éš”ï¼Œä¾‹å¦‚ï¼šå…šæ”¿å†›,æŸæœºæ„,æŸèŒåŠ¡,æŸéƒ¨é˜Ÿ...",
                help="ä¼šæå‡ä½ å…³å¿ƒçš„èŠ‚ç‚¹/äº‹ä»¶æƒé‡ï¼Œå¸®åŠ©ä¿ç•™æ›´å¤šç›¸å…³å…³ç³»"
            )
            min_weight = st.slider(
                "ä¿ç•™å…³ç³»æœ€ä½æƒé‡",
                min_value=1,
                max_value=10,
                value=3,
                step=1,
                help="Recall ä¼˜å…ˆå»ºè®® 2-4ï¼šè¶Šä½è¶Šä¸æ¼ï¼ˆä½†æ›´å†—ä½™ï¼‰"
            )
            top_per_event = st.slider(
                "æ¯ä¸ªäº‹ä»¶è‡³å°‘ä¿ç•™å‰ N æ¡å…³ç³»",
                min_value=3,
                max_value=30,
                value=12,
                step=1,
                help="Recall ä¼˜å…ˆå»ºè®® 10-15ï¼šä¿è¯æ¯ä¸ªäº‹ä»¶ä¸è¢«å‰ªç˜¦"
            )
        
        files = st.file_uploader("ä¸Šä¼ æ–‡æ¡£", accept_multiple_files=True, type=["pdf", "epub", "docx", "txt"],
                                 label_visibility="collapsed")
        
        if files:
            st.markdown(f"<p style='text-align:center; color:#86868b;'>å·²é€‰æ‹© {len(files)} ä¸ªæ–‡ä»¶</p>", 
                       unsafe_allow_html=True)
            
            if st.button("å¼€å§‹åˆ†æ", use_container_width=True):
                if not api_key:
                    st.error("è¯·å¡«å†™ API Key")
                else:
                    all_text = ""
                    for f in files:
                        all_text += read_file(f) + "\n\n"
                    
                    if len(all_text.strip()) < 100:
                        st.error("æ–‡ä»¶å†…å®¹è¿‡å°‘")
                    else:
                        st.session_state.text_content = all_text
                        st.session_state.global_context = global_context
                        client = get_client(api_key)
                        
                        mode = "hybrid" if "æ··åˆ" in chunk_mode else ("rule" if "è§„åˆ™" in chunk_mode else "fixed")
                        
                        # ä¸Šä¸‹æ–‡æ³¨å…¥æŠ½å–ï¼ˆåˆ†å—å¤„ç†ï¼‰
                        with st.spinner("æ­£åœ¨è¿›è¡Œä¸Šä¸‹æ–‡æ³¨å…¥æŠ½å–..."):
                            batches = process_book_pipeline(
                                all_text, client, model,
                                global_context=global_context,
                                chunk_mode=mode,
                                llm_budget=llm_budget
                            )
                            entities, events, relations = aggregate_graph_batches(batches)
                            
                            # æ•´åˆå­¤ç«‹èŠ‚ç‚¹
                            orphan_entities, orphan_events = find_orphan_nodes(entities, events, relations)
                            if orphan_entities or orphan_events:
                                st.info(f"ğŸ”— æ­£åœ¨æ•´åˆ {len(orphan_entities)} ä¸ªå­¤ç«‹å®ä½“, {len(orphan_events)} ä¸ªå­¤ç«‹äº‹ä»¶...")
                                extra_relations = integrate_orphans(
                                    client, model, 
                                    orphan_entities, orphan_events,
                                    entities, events
                                )
                                relations.extend(extra_relations)

                        extra_focus = [s.strip() for s in (focus_extra_raw or "").split(",") if s.strip()]

                        # å…³ç³»å»å†—ä½™ï¼šä»¥äº‹ä»¶ä¸ºä¸­å¿ƒï¼Œç¡®ä¿æ¯ä¸ªäº‹ä»¶æœ‰ top-Nï¼ŒåŒæ—¶æŒ‰æƒé‡è¿‡æ»¤
                        entities, events, relations, stats = prioritize_graph(
                            entities, events, relations,
                            min_weight=min_weight,
                            top_per_event=top_per_event,
                            extra_focus=extra_focus
                        )
                        st.session_state.focus_stats = stats

                        st.info(f"ğŸ“„ åˆ‡åˆ†å®Œæˆ: {len(batches)} å— Â· ç²¾é€‰å {len(relations)} æ¡å…³ç³»")
                        
                        if events:
                            st.session_state.entities = entities
                            st.session_state.events = events
                            st.session_state.relations = relations
                            st.success(f"âœ… å®Œæˆ: {len(entities)} å®ä½“, {len(events)} äº‹ä»¶, {len(relations)} å…³ç³»")
                            st.session_state.step = 2
                            st.rerun()
                        else:
                            st.error("æœªè¯†åˆ«åˆ°äº‹ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡æ¡£å†…å®¹")

# ============================================
# Step 2: Review Events & Entities
# ============================================
elif st.session_state.step == 2:
    st.markdown("""
    <div style="text-align:center; padding:30px 0 40px; background: linear-gradient(180deg, rgba(196,30,58,0.05) 0%, #fff 100%);">
        <div class="hero-badge" style="margin-bottom:16px;">å†…å®¹å®¡æ ¸</div>
        <h1 style="font-size:32px; color:#C41E3A; letter-spacing:0.1em;">å®¡æ ¸ä¸è°ƒæ•´</h1>
        <p style="color:#7a7a7a; font-size:14px;">æŸ¥çœ‹æŠ½å–çš„äº‹ä»¶å’Œå®ä½“ï¼Œè°ƒæ•´é£é™©ç­‰çº§</p>
    </div>
    """, unsafe_allow_html=True)
    
    entities = st.session_state.entities
    events = st.session_state.events
    relations = st.session_state.relations
    
    # Stats
    focus_stats = st.session_state.focus_stats or {"nodes": 0, "relations": 0}
    col1, col2, col3, col4, col5, col6 = st.columns(6)
    with col1:
        st.metric("å®ä½“æ•°", len(entities))
    with col2:
        st.metric("äº‹ä»¶æ•°", len(events))
    with col3:
        st.metric("å…³ç³»æ•°", len(relations))
    with col4:
        high_risk = sum(1 for e in events if e.get("risk_level") == "HIGH_RISK")
        st.metric("é«˜é£é™©äº‹ä»¶", high_risk)
    with col5:
        st.metric("é‡ç‚¹èŠ‚ç‚¹", focus_stats.get("nodes", 0))
    with col6:
        st.metric("é‡ç‚¹å…³ç³»", focus_stats.get("relations", 0))
    
    st.markdown("<br>", unsafe_allow_html=True)
    
    # Tabs
    tab1, tab2, tab3 = st.tabs(["ğŸ“… äº‹ä»¶", "ğŸ‘¤ å®ä½“", "ğŸ”— å…³ç³»"])
    
    with tab1:
        st.markdown("#### äº‹ä»¶åˆ—è¡¨ï¼ˆæŒ‰é£é™©æ’åºï¼‰")
        
        # æŒ‰é£é™©ç­‰çº§æ’åº
        risk_order = {"HIGH_RISK": 0, "CONTROVERSIAL": 1, "SAFE": 2}
        sorted_events = sorted(events, key=lambda x: risk_order.get(x.get("risk_level", "SAFE"), 2))
        
        for ev in sorted_events:
            risk = ev.get("risk_level", "SAFE")
            risk_class = f"risk-{risk.lower().replace('_', '-')}"
            type_class = f"event-{ev.get('type', 'MEETING').lower()}"
            
            st.markdown(f"""
            <div class="event-card">
                <div style="display:flex; justify-content:space-between; align-items:center;">
                    <span class="event-title">{ev.get('name', 'æœªçŸ¥äº‹ä»¶')}</span>
                    <span class="risk-tag {risk_class}">{RISK_LEVEL_CN.get(risk, risk)}</span>
                </div>
                <div class="event-meta">
                    <span class="type-tag {type_class}">{EVENT_TYPE_CN.get(ev.get('type'), ev.get('type'))}</span>
                    ğŸ“… {ev.get('time_str', 'æ—¶é—´æœªçŸ¥')}
                </div>
                <div class="event-desc">{ev.get('description', '')}</div>
                <div style="margin-top:10px; padding-top:10px; border-top:1px solid #f0f0f0;">
                    <strong style="font-size:13px; color:#6e6e73;">æ”¿æ²»å®šæ€§:</strong>
                    <span style="font-size:13px; color:#1d1d1f;">{ev.get('political_significance', 'æœªå®šæ€§')}</span>
                </div>
            </div>
            """, unsafe_allow_html=True)
    
    with tab2:
        st.markdown("#### å®ä½“åˆ—è¡¨")
        
        # æŒ‰ç±»å‹åˆ†ç»„
        by_type = defaultdict(list)
        for e in entities:
            by_type[e.get("type", "OTHER")].append(e)
        
        for etype in ["PERSON", "ORG", "LOCATION", "DOCUMENT", "CONCEPT"]:
            if etype not in by_type:
                continue
            elist = by_type[etype]
            type_class = f"type-{etype.lower()}"
            
            with st.expander(f"**{ENTITY_TYPE_CN.get(etype, etype)}** Â· {len(elist)} ä¸ª", expanded=(etype == "PERSON")):
                for e in elist:
                    alias_str = f" ({', '.join(e.get('alias', []))})" if e.get('alias') else ""
                    st.markdown(f"""
                    <div style="padding:8px 12px; margin:4px 0; background:#f5f5f7; border-radius:8px;">
                        <span class="type-tag {type_class}">{etype}</span>
                        <strong>{e.get('name', '')}</strong>
                        <span style="color:#86868b;">{alias_str}</span>
                    </div>
                    """, unsafe_allow_html=True)
    
    with tab3:
        st.markdown("#### å…³ç³»åˆ—è¡¨")
        
        for r in relations[:50]:
            rel_cn = RELATION_TYPE_CN.get(r.get("relation"), r.get("relation"))
            st.markdown(f"""
            <div style="padding:10px 14px; margin:6px 0; background:#f5f5f7; border-radius:8px;">
                <strong>{r.get('source_id', '')}</strong>
                <span style="color:#0071e3; margin:0 8px;">â€”[ {rel_cn} ]â†’</span>
                <strong>{r.get('target_id', '')}</strong>
                <div style="font-size:12px; color:#86868b; margin-top:4px;">{r.get('details', '')}</div>
            </div>
            """, unsafe_allow_html=True)
        
        if len(relations) > 50:
            st.markdown(f"<p style='color:#86868b;'>... è¿˜æœ‰ {len(relations)-50} æ¡å…³ç³»</p>", unsafe_allow_html=True)
    
    # Navigation
    st.markdown("<br>", unsafe_allow_html=True)
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        c1, c2 = st.columns(2)
        with c1:
            if st.button("â† é‡æ–°ä¸Šä¼ ", use_container_width=True):
                st.session_state.step = 1
                st.rerun()
        with c2:
            if st.button("ç”Ÿæˆå›¾è°± â†’", use_container_width=True, type="primary"):
                st.session_state.step = 3
                st.rerun()

# ============================================
# Step 3: Graph Visualization
# ============================================
elif st.session_state.step == 3:
    st.markdown("""
    <div style="text-align:center; padding:30px 0 30px; background: linear-gradient(180deg, rgba(196,30,58,0.05) 0%, #fff 100%);">
        <div class="hero-badge" style="margin-bottom:16px;">å¯è§†åŒ–å±•ç¤º</div>
        <h1 style="font-size:32px; color:#C41E3A; letter-spacing:0.1em;">äº‹ä»¶çŸ¥è¯†å›¾è°±</h1>
        <p style="color:#7a7a7a; font-size:14px;">â—† è±å½¢ä¸ºäº‹ä»¶èŠ‚ç‚¹ &nbsp;|&nbsp; â— åœ†å½¢ä¸ºå®ä½“èŠ‚ç‚¹</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Filters
    col1, col2, col3, col4 = st.columns([2, 2, 1, 1])
    with col1:
        show_types = st.multiselect(
            "æ˜¾ç¤ºäº‹ä»¶ç±»å‹",
            options=list(EVENT_TYPE_CN.keys()),
            default=list(EVENT_TYPE_CN.keys()),
            format_func=lambda x: EVENT_TYPE_CN.get(x, x)
        )
    with col2:
        show_risks = st.multiselect(
            "æ˜¾ç¤ºé£é™©ç­‰çº§",
            options=list(RISK_LEVEL_CN.keys()),
            default=list(RISK_LEVEL_CN.keys()),
            format_func=lambda x: RISK_LEVEL_CN.get(x, x)
        )
    with col3:
        layout = st.selectbox("å¸ƒå±€", ["åŠ›å¯¼å‘", "å±‚æ¬¡å¸ƒå±€"])
    with col4:
        sparse_threshold = st.number_input("æ•£ç‚¹è¡¥é“¾é˜ˆå€¼", min_value=1, max_value=5, value=2, help="å…³ç³»æ•°â‰¤æ­¤å€¼ä¼šå°è¯•è¡¥é“¾ï¼Œè¡¥ä¸ä¸Šåˆ™è¿›å…¥æ•æ„Ÿè¯åº“")
    
    # è¿‡æ»¤äº‹ä»¶
    filtered_events = [
        e for e in st.session_state.events
        if e.get("type") in show_types and e.get("risk_level", "SAFE") in show_risks
    ]
    
    # è¿‡æ»¤å…³ç³»ï¼ˆåªä¿ç•™ä¸è¿‡æ»¤åäº‹ä»¶ç›¸å…³çš„ï¼‰
    event_ids = {e["id"] for e in filtered_events}
    filtered_relations = [
        r for r in st.session_state.relations
        if r["source_id"] in event_ids or r["target_id"] in event_ids
    ]
    
    # è¿‡æ»¤å®ä½“ï¼ˆåªä¿ç•™æœ‰å…³ç³»çš„ï¼‰
    involved_ids = set()
    for r in filtered_relations:
        involved_ids.add(r["source_id"])
        involved_ids.add(r["target_id"])
    
    filtered_entities = [e for e in st.session_state.entities if e["id"] in involved_ids]
    
    # è¯†åˆ«æ•£ç‚¹ï¼ˆå…³ç³»ç¨€ç–çš„èŠ‚ç‚¹ï¼‰
    main_entities, main_events, sparse_entities, sparse_events = find_sparse_nodes(
        filtered_entities, filtered_events, filtered_relations, max_relations=sparse_threshold
    )
    
    # æ„å»ºæ•æ„Ÿè¯åº“èŠ‚ç‚¹ï¼ˆæ•£ç‚¹å½’å…¥æ­¤å¤„ï¼‰
    sensitive_node = build_sensitive_node(sparse_entities, sparse_events)
    
    # ä¸»å›¾åªä¿ç•™å…³ç³»å¯†é›†çš„èŠ‚ç‚¹
    main_ids = set([e["id"] for e in main_entities] + [ev["id"] for ev in main_events])
    main_relations = [
        r for r in filtered_relations
        if r.get("source_id") in main_ids and r.get("target_id") in main_ids
    ]
    
    sensitive_count = len(sparse_entities) + len(sparse_events)
    st.markdown(
        f"<p style='text-align:center; color:#86868b;'>ä¸»å›¾: {len(main_events)} äº‹ä»¶, {len(main_entities)} å®ä½“, {len(main_relations)} å…³ç³»"
        + (f" Â· <b>æ•æ„Ÿè¯åº“: {sensitive_count} é¡¹</b>" if sensitive_count > 0 else "") + "</p>", 
        unsafe_allow_html=True
    )
    
    # Build & Display Graph
    G = build_event_graph(main_entities, main_events, main_relations, sensitive_node)
    
    net = Network(height="600px", width="100%", bgcolor="#ffffff", font_color="#1d1d1f", directed=True)
    net.from_nx(G)
    
    if layout == "å±‚æ¬¡å¸ƒå±€":
        net.set_options('''
        {
          "layout": {"hierarchical": {"enabled": true, "direction": "UD", "sortMethod": "directed"}},
          "physics": {"enabled": false},
          "edges": {"smooth": {"type": "cubicBezier"}, "font": {"size": 11}},
          "interaction": {"hover": true, "navigationButtons": true}
        }
        ''')
    else:
        net.set_options('''
        {
          "physics": {
            "solver": "forceAtlas2Based",
            "forceAtlas2Based": {"gravitationalConstant": -100, "springLength": 150},
            "stabilization": {"iterations": 200}
          },
          "edges": {"smooth": {"type": "continuous"}, "font": {"size": 11}},
          "interaction": {"hover": true, "navigationButtons": true}
        }
        ''')
    
    st.components.v1.html(net.generate_html(), height=620)
    
    # Legend
    st.markdown("""
    <div style="display:flex; justify-content:center; gap:20px; margin-top:16px; flex-wrap:wrap; padding:12px 20px; background:#fafafa; border:1px solid #e5e5e5;">
        <span style="font-size:12px; color:#4a4a4a;"><span style="color:#1565c0;">â—†</span> ä¼šè®®</span>
        <span style="font-size:12px; color:#4a4a4a;"><span style="color:#c62828;">â—†</span> å†²çª</span>
        <span style="font-size:12px; color:#4a4a4a;"><span style="color:#2e7d32;">â—†</span> è®²è¯</span>
        <span style="font-size:12px; color:#4a4a4a;"><span style="color:#7b1fa2;">â—†</span> æ”¿ç­–</span>
        <span style="font-size:12px; color:#4a4a4a;"><span style="color:#f57c00;">â—†</span> è¿åŠ¨</span>
        <span style="color:#ccc;">|</span>
        <span style="font-size:12px; color:#4a4a4a;"><span style="color:#c62828;">â—</span> äººç‰©</span>
        <span style="font-size:12px; color:#4a4a4a;"><span style="color:#2e7d32;">â—</span> ç»„ç»‡</span>
        <span style="font-size:12px; color:#4a4a4a;"><span style="color:#1565c0;">â—</span> åœ°ç‚¹</span>
        <span style="font-size:12px; color:#4a4a4a;"><span style="color:#7b1fa2;">â—</span> æ–‡ä»¶</span>
        <span style="font-size:12px; color:#4a4a4a;"><span style="color:#f57c00;">â—</span> æ¦‚å¿µ</span>
    </div>
    """, unsafe_allow_html=True)
    
    # æ•æ„Ÿè¯åº“è¯¦æƒ…å±•å¼€
    if sensitive_node:
        sensitive_count = len(sensitive_node.get("items", []))
        with st.expander(f"âš ï¸ æ•æ„Ÿè¯åº“è¯¦æƒ… ({sensitive_count} é¡¹)", expanded=False):
            items = sensitive_node.get("items", [])
            st.markdown("\n".join(items[:200]) + ("\n..." if len(items) > 200 else ""))
    
    # Export
    st.markdown("<br>", unsafe_allow_html=True)
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        export_data = {
            "entities": st.session_state.entities,
            "events": st.session_state.events,
            "relations": st.session_state.relations
        }
        c1, c2 = st.columns(2)
        with c1:
            st.download_button(
                "ğŸ“¥ ä¸‹è½½ JSON",
                json.dumps(export_data, ensure_ascii=False, indent=2),
                "event_graph.json",
                use_container_width=True
            )
        with c2:
            if st.button("â† è¿”å›å®¡æ ¸", use_container_width=True):
                st.session_state.step = 2
                st.rerun()
