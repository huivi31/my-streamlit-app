import streamlit as st
import os, json, time, concurrent.futures, io, tempfile, re
from collections import Counter, defaultdict
import pypdf
from docx import Document
import ebooklib
from ebooklib import epub
from bs4 import BeautifulSoup
from google import genai
from pyvis.network import Network
import networkx as nx

# ç¤¾åŒºæ£€æµ‹ï¼ˆå¯é€‰ï¼‰
try:
    import community as community_louvain
    HAS_LOUVAIN = True
except Exception:
    HAS_LOUVAIN = False

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="DeepGraph Pro v3 - æ•æ„Ÿå†…å®¹åˆ†æ",
    layout="wide",
    page_icon="ğŸ”",
    initial_sidebar_state="expanded"
)

# --- æœªæ¥æ„Ÿ + æ¯›ç»ç’ƒ UI ---
st.markdown(
    """
<style>
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');
:root {
  --bg1:#0c1224; --bg2:#0f1b2f; --card:rgba(255,255,255,0.08);
  --border:rgba(255,255,255,0.16); --primary:#4ae0c8; --accent:#7c6bff; --accent2:#18b4e6;
  --danger:#ff4444; --warning:#ffaa00; --safe:#44bb44;
}
.stApp {
  background:
    radial-gradient(120% 120% at 20% 20%, rgba(74,224,200,0.20), transparent 40%),
    radial-gradient(90% 90% at 80% 0%, rgba(124,107,255,0.18), transparent 42%),
    linear-gradient(145deg, var(--bg1), var(--bg2));
  color:#e6edf7; font-family:'Inter',sans-serif;
}
.glass-card {
  background:var(--card); border:1px solid var(--border);
  backdrop-filter:blur(20px) saturate(1.4); -webkit-backdrop-filter:blur(20px) saturate(1.4);
  box-shadow:0 18px 48px rgba(16,185,240,0.18), 0 18px 48px rgba(124,107,255,0.12);
  border-radius:18px; padding:18px 18px 14px; transition:all 180ms ease;
}
.glass-card:hover { transform:translateY(-2px); box-shadow:0 22px 52px rgba(16,185,240,0.28), 0 22px 52px rgba(124,107,255,0.18); }
.stButton > button, .stDownloadButton > button {
  background:linear-gradient(120deg, var(--primary), var(--accent));
  color:#fff; border:none; border-radius:12px; height:44px; font-weight:700; letter-spacing:0.2px;
  box-shadow:0 14px 30px rgba(72,211,200,0.35); transition:all 140ms ease;
}
.stButton > button:hover, .stDownloadButton > button:hover {
  filter:brightness(1.06); box-shadow:0 16px 36px rgba(124,107,255,0.35); transform:translateY(-1px);
}
.stTextInput > div > div > input, .stTextArea > div > textarea, .stSelectbox > div > div > div {
  background:rgba(255,255,255,0.06) !important; border:1px solid var(--border) !important;
  border-radius:12px !important; color:#e5e7eb !important;
}
.stProgress > div > div { background:rgba(255,255,255,0.08); border-radius:999px; }
.stProgress > div > div > div {
  background:linear-gradient(120deg, var(--primary), var(--accent2));
  box-shadow:0 6px 18px rgba(72,211,200,0.35);
}
.risk-high { background:rgba(255,68,68,0.2); border-left:4px solid #ff4444; padding:10px; margin:5px 0; border-radius:8px; }
.risk-medium { background:rgba(255,170,0,0.2); border-left:4px solid #ffaa00; padding:10px; margin:5px 0; border-radius:8px; }
.risk-low { background:rgba(68,187,68,0.2); border-left:4px solid #44bb44; padding:10px; margin:5px 0; border-radius:8px; }
.dimension-badge {
  display:inline-block; padding:4px 10px; border-radius:999px; font-weight:600; font-size:0.75em; margin:2px;
}
.dim-history { background:rgba(255,68,68,0.3); color:#ff6666; }
.dim-political { background:rgba(255,170,0,0.3); color:#ffcc00; }
.dim-sentiment { background:rgba(255,255,68,0.3); color:#ffff66; }
.dim-event { background:rgba(170,68,255,0.3); color:#cc99ff; }
</style>
    """,
    unsafe_allow_html=True,
)

# --- çŠ¶æ€ç®¡ç† ---
if "processed" not in st.session_state:
    st.session_state.processed = False
if "graph_html" not in st.session_state:
    st.session_state.graph_html = ""
if "report_txt" not in st.session_state:
    st.session_state.report_txt = ""
if "sensitive_points" not in st.session_state:
    st.session_state.sensitive_points = []

# --- å‚æ•°é…ç½® ---
MAX_WORKERS = 6
CHUNK_LEN = 2500  # å‡å°å—å¤§å°ä»¥ä¿ç•™æ›´å¤šä¸Šä¸‹æ–‡

# ============================================
# æ•æ„Ÿç»´åº¦å®šä¹‰
# ============================================

SENSITIVE_DIMENSIONS = {
    "history_nihilism": {
        "name": "å†å²è™šæ— ",
        "color": "#ff4444",
        "keywords": ["å¦å®š", "æŠ¹é»‘", "æ±¡è”‘", "æ­ªæ›²å†å²", "å†å²è™šæ— ", "è‹±çƒˆ", "çƒˆå£«", "é©å‘½", "æŠ—æ—¥", "è§£æ”¾", "å»ºå…š", "å»ºå›½",
                    "æ–‡é©", "å¤§è·ƒè¿›", "åå³", "åœŸæ”¹", "ä¸‰å¹´å›°éš¾", "é¥¥è’", "æ­»äº¡äººæ•°", "çœŸç›¸"],
        "desc": "å¦å®šå…šå²ã€æŠ¹é»‘è‹±çƒˆã€ç¾åŒ–åé¢äººç‰©ã€æ­ªæ›²é‡å¤§å†å²äº‹ä»¶"
    },
    "political_stance": {
        "name": "æ”¿æ²»ç«‹åœº",
        "color": "#ffaa00",
        "keywords": ["é¢†å¯¼äºº", "æ€»ä¹¦è®°", "ä¸»å¸­", "æ”¿ç­–", "åˆ¶åº¦", "ä½“åˆ¶", "æ°‘ä¸»", "è‡ªç”±", "äººæƒ", "ç‹¬è£", "ä¸“åˆ¶",
                    "å¢ƒå¤–åŠ¿åŠ›", "å¤–åª’", "è¥¿æ–¹", "ç¾å›½", "æ•Œå¯¹", "æ¸—é€", "å¹²æ¶‰å†…æ”¿", "é¢ è¦†"],
        "desc": "æš—è®½é¢†å¯¼äººã€è´¨ç–‘æ”¿ç­–åˆ¶åº¦ã€ä¼ æ’­å¢ƒå¤–å£å¾„"
    },
    "sentiment_incite": {
        "name": "èˆ†æƒ…ç…½åŠ¨",
        "color": "#ffff44",
        "keywords": ["æ„¤æ€’", "æŠ—è®®", "ä¸æ»¡", "ç»´æƒ", "ä¸Šè®¿", "è¯·æ„¿", "ç½¢å·¥", "ç½¢è¯¾", "é›†ä¼š", "æ¸¸è¡Œ", "ç¤ºå¨",
                    "å®˜é€¼æ°‘å", "è´ªè…", "ä¸å…¬", "é»‘å¹•", "çœŸç›¸", "æ­éœ²", "æ›å…‰"],
        "desc": "ç…½åŠ¨æƒ…ç»ªã€åˆ¶é€ å¯¹ç«‹ã€æ”¾å¤§è´Ÿé¢ã€æ¿€åŒ–çŸ›ç›¾"
    },
    "sensitive_event": {
        "name": "æ•æ„Ÿäº‹ä»¶",
        "color": "#aa44ff",
        "keywords": ["å…­å››", "å¤©å®‰é—¨", "89", "64", "æ³•è½®åŠŸ", "è½®å­", "å°ç‹¬", "è—ç‹¬", "ç–†ç‹¬", "æ¸¯ç‹¬",
                    "æ–°ç–†", "è¥¿è—", "é¦™æ¸¯", "å°æ¹¾", "ç»Ÿä¸€", "ç‹¬ç«‹", "åˆ†è£‚", "é¢œè‰²é©å‘½", "èŒ‰è‰èŠ±"],
        "desc": "å¼•ç”¨æ•æ„Ÿå†å²èŠ‚ç‚¹ã€æš—ç¤ºç»´ç¨³äº‹ä»¶ã€è§¦åŠçº¢çº¿è¯é¢˜"
    }
}

# é£é™©ç­‰çº§å®šä¹‰
RISK_LEVELS = {
    "high": {"name": "é«˜å±", "color": "#ff4444", "size": 35, "border": 4},
    "medium": {"name": "ä¸­å±", "color": "#ffaa00", "size": 25, "border": 2},
    "low": {"name": "ä½å±", "color": "#44bb44", "size": 18, "border": 1}
}

# ============================================
# é˜¶æ®µ1ï¼šæ•æ„Ÿç‚¹è¯†åˆ« Prompt
# ============================================

SENSITIVE_SCAN_PROMPT = """
ä½ æ˜¯äº’è”ç½‘å†…å®¹å®¡æ ¸ä¸“å®¶ï¼Œä¸“é—¨è¯†åˆ«ä¸ç¬¦åˆä¸­å›½å®˜æ–¹å®£ä¼ å£å¾„çš„æ•æ„Ÿå†…å®¹ã€‚

è¯·ä»”ç»†åˆ†æä»¥ä¸‹æ–‡æœ¬ï¼Œè¯†åˆ«å…¶ä¸­çš„æ•æ„Ÿç‚¹ï¼š

ã€æ•æ„Ÿç»´åº¦ã€‘
1. å†å²è™šæ—  (history_nihilism): å¦å®šå…šå²ã€æŠ¹é»‘è‹±çƒˆã€ç¾åŒ–åé¢äººç‰©ã€æ­ªæ›²é‡å¤§å†å²äº‹ä»¶
2. æ”¿æ²»ç«‹åœº (political_stance): æš—è®½é¢†å¯¼äººã€è´¨ç–‘æ”¿ç­–åˆ¶åº¦ã€ä¼ æ’­å¢ƒå¤–å£å¾„
3. èˆ†æƒ…ç…½åŠ¨ (sentiment_incite): ç…½åŠ¨æƒ…ç»ªã€åˆ¶é€ å¯¹ç«‹ã€æ”¾å¤§è´Ÿé¢ã€æ¿€åŒ–çŸ›ç›¾
4. æ•æ„Ÿäº‹ä»¶ (sensitive_event): å¼•ç”¨æ•æ„Ÿå†å²èŠ‚ç‚¹ã€æš—ç¤ºç»´ç¨³äº‹ä»¶ã€è§¦åŠçº¢çº¿è¯é¢˜

ã€ç‰¹åˆ«æ³¨æ„ã€‘
- è¯†åˆ«éšæ™¦è¡¨è¾¾ï¼šåè¯ã€è®½åˆºã€"é˜´é˜³æ€ªæ°”"ã€å€Ÿå¤è®½ä»Š
- è¯†åˆ«éšå–»æŒ‡ä»£ï¼šç”¨ä»£å·ã€è°éŸ³ã€å†å²å…¸æ•…æš—æŒ‡æ•æ„Ÿå†…å®¹
- è¯†åˆ«ç«‹åœºå€¾å‘ï¼šä½œè€…æ˜¯åœ¨æ‰¹è¯„è¿˜æ˜¯æ”¯æŒï¼Œæ˜¯å®¢è§‚é™ˆè¿°è¿˜æ˜¯å¸¦æœ‰å€¾å‘

ã€è¾“å‡ºæ ¼å¼ã€‘
è¿”å› JSON æ•°ç»„ï¼Œæ¯ä¸ªæ•æ„Ÿç‚¹åŒ…å«ï¼š
- "content": åŸæ–‡ä¸­çš„æ•æ„Ÿå†…å®¹ï¼ˆä¿ç•™åŸæ–‡ï¼‰
- "dimension": æ•æ„Ÿç»´åº¦ä»£ç 
- "risk_level": é£é™©ç­‰çº§ (high/medium/low)
- "interpretation": è¿™æ®µè¯å®é™…åœ¨æš—ç¤º/è¡¨è¾¾ä»€ä¹ˆ
- "entities": æ¶‰åŠçš„å®ä½“ï¼ˆäººç‰©ã€ç»„ç»‡ã€äº‹ä»¶ï¼‰åˆ—è¡¨
- "stance": ä½œè€…ç«‹åœº (attack/support/neutral/sarcasm)

è‹¥æ— æ•æ„Ÿå†…å®¹ï¼Œè¿”å› []ã€‚

ã€å¾…åˆ†ææ–‡æœ¬ã€‘
{text}
"""

# ============================================
# é˜¶æ®µ2ï¼šå…³ç³»æ„å»º Prompt
# ============================================

RELATION_BUILD_PROMPT = """
åŸºäºå·²è¯†åˆ«çš„æ•æ„Ÿç‚¹ï¼Œæ„å»ºå®ä½“å…³ç³»ç½‘ç»œã€‚

ã€å·²è¯†åˆ«æ•æ„Ÿç‚¹ã€‘
{sensitive_points}

ã€åŸæ–‡ã€‘
{text}

ã€ä»»åŠ¡ã€‘
1. æå–æ‰€æœ‰æ¶‰åŠçš„å®ä½“ï¼ˆäººç‰©ã€ç»„ç»‡ã€äº‹ä»¶ã€æ¦‚å¿µï¼‰
2. æ„å»ºå®ä½“ä¹‹é—´çš„å…³ç³»ï¼Œç‰¹åˆ«å…³æ³¨ï¼š
   - æ”»å‡»/æ‰¹è¯„å…³ç³»ï¼ˆè°åœ¨æ‰¹è¯„/æ”»å‡»è°ï¼‰
   - æ”¯æŒ/è¾©æŠ¤å…³ç³»ï¼ˆè°åœ¨ä¸ºè°è¾©æŠ¤ï¼‰
   - éšæ™¦æŒ‡å‘ï¼ˆç”¨Aæš—å–»Bçš„å…³ç³»ï¼‰
   - å¯¹ç«‹å…³ç³»ï¼ˆå“ªäº›å®ä½“ç«™åœ¨å¯¹ç«‹é¢ï¼‰

ã€è¾“å‡ºæ ¼å¼ã€‘
è¿”å› JSON æ•°ç»„ï¼Œæ¯ä¸ªå…³ç³»åŒ…å«ï¼š
- "head": ä¸»ä½“å®ä½“
- "relation": å…³ç³»æè¿°ï¼ˆä¿ç•™å…·ä½“åŠ¨ä½œï¼‰
- "tail": å®¢ä½“å®ä½“
- "type_head": å®ä½“ç±»å‹ (Person/Org/Event/Concept)
- "type_tail": å®ä½“ç±»å‹
- "relation_type": å…³ç³»ç±»å‹ (attack/support/imply/oppose/neutral)
- "risk_level": è¿™æ¡å…³ç³»çš„é£é™©ç­‰çº§ (high/medium/low)
- "evidence": æ”¯æ’‘è¿™ä¸ªå…³ç³»çš„åŸæ–‡è¯æ®
"""

# ============================================
# éšå–»/æš—ç¤ºè¯†åˆ« Prompt
# ============================================

METAPHOR_PROMPT = """
åˆ†æä»¥ä¸‹æ–‡æœ¬ä¸­çš„éšæ™¦è¡¨è¾¾å’Œæ·±å±‚å«ä¹‰ï¼š

ã€æ–‡æœ¬ã€‘
{text}

ã€åˆ†æç»´åº¦ã€‘
1. **æš—è®½è¯†åˆ«**ï¼šæ˜¯å¦ä½¿ç”¨åè¯ã€è®½åˆºã€"é˜´é˜³æ€ªæ°”"ï¼Ÿå…·ä½“æ˜¯åœ¨è®½åˆºä»€ä¹ˆï¼Ÿ
2. **éšå–»è§£è¯»**ï¼šå¦‚æœä½¿ç”¨äº†éšå–»ã€å…¸æ•…ã€ä»£å·ã€è°éŸ³ï¼Œå®é™…åœ¨æŒ‡å‘ä»€ä¹ˆï¼Ÿ
3. **å€Ÿå¤è®½ä»Š**ï¼šæ˜¯å¦å€Ÿå†å²äº‹ä»¶/äººç‰©æš—å–»å½“å‰ï¼ŸæŒ‡å‘çš„æ˜¯ä»€ä¹ˆï¼Ÿ
4. **ç«‹åœºåˆ¤æ–­**ï¼šä½œè€…çš„çœŸå®ç«‹åœºæ˜¯ä»€ä¹ˆï¼Ÿè¡¨é¢ä¸­ç«‹å®é™…åœ¨è¡¨è¾¾ä»€ä¹ˆï¼Ÿ
5. **ä¼ æ’­é£é™©**ï¼šè¿™æ®µå†…å®¹å¦‚æœä¼ æ’­ï¼Œå¯èƒ½è¢«å¦‚ä½•è§£è¯»ï¼Ÿ

ã€è¾“å‡ºæ ¼å¼ã€‘
è¿”å› JSONï¼š
{{
  "has_metaphor": true/false,
  "metaphors": [
    {{
      "surface": "è¡¨é¢è¡¨è¾¾",
      "actual_meaning": "å®é™…å«ä¹‰",
      "target": "æŒ‡å‘çš„æ•æ„Ÿç›®æ ‡",
      "technique": "ä½¿ç”¨çš„æŠ€å·§(åè®½/éšå–»/å€Ÿå¤è®½ä»Š/è°éŸ³ç­‰)"
    }}
  ],
  "author_stance": "ä½œè€…çœŸå®ç«‹åœº",
  "risk_assessment": "ä¼ æ’­é£é™©è¯„ä¼°"
}}
"""

# ============================================
# å…³ç³»æ¨ç† Prompt
# ============================================

INFERENCE_PROMPT = """
åŸºäºå·²æŠ½å–çš„å…³ç³»ï¼Œæ¨ç†éšå«å…³è”ï¼š

ã€å·²çŸ¥å…³ç³»ã€‘
{existing_relations}

ã€æ¨ç†ä»»åŠ¡ã€‘
1. å¦‚æœ Aæ”»å‡»Bï¼ŒBæ”»å‡»Cï¼Œé‚£ä¹ˆAå’ŒCæ˜¯ä»€ä¹ˆå…³ç³»ï¼Ÿ
2. å“ªäº›å®ä½“è™½ç„¶æ²¡æœ‰ç›´æ¥å…³è”ï¼Œä½†å±äºåŒä¸€é˜µè¥ï¼Ÿ
3. å“ªäº›å®ä½“å¤„äºå¯¹ç«‹é˜µè¥ï¼Ÿ
4. è¿™äº›å…³ç³»æ­ç¤ºäº†ä»€ä¹ˆæ ¸å¿ƒçŸ›ç›¾æˆ–æ•æ„Ÿä¸»é¢˜ï¼Ÿ

ã€è¾“å‡ºæ ¼å¼ã€‘
è¿”å› JSONï¼š
{{
  "inferred_relations": [
    {{"head": "å®ä½“A", "relation": "æ¨ç†å‡ºçš„å…³ç³»", "tail": "å®ä½“B", "confidence": 0.8}}
  ],
  "camps": [
    {{"name": "é˜µè¥åç§°", "members": ["å®ä½“1", "å®ä½“2"], "stance": "ç«‹åœºæè¿°"}}
  ],
  "core_conflicts": ["æ ¸å¿ƒçŸ›ç›¾1", "æ ¸å¿ƒçŸ›ç›¾2"],
  "main_sensitive_theme": "æ ¸å¿ƒæ•æ„Ÿä¸»é¢˜"
}}
"""

# ============================================
# è¾…åŠ©å‡½æ•°
# ============================================

def smart_split(text, max_len=CHUNK_LEN):
    """æŒ‰æ®µè½è¾¹ç•Œåˆ†å—ï¼Œä¿æŒè¯­ä¹‰å®Œæ•´æ€§"""
    paragraphs = re.split(r'\n\s*\n|\n(?=[ç¬¬ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+[ç« èŠ‚æ¡æ¬¾])', text)
    chunks = []
    current = ""
    
    for p in paragraphs:
        p = p.strip()
        if not p:
            continue
        if len(current) + len(p) + 1 < max_len:
            current += "\n\n" + p if current else p
        else:
            if current:
                chunks.append(current.strip())
            if len(p) > max_len:
                sentences = re.split(r'(?<=[ã€‚ï¼ï¼Ÿï¼›])', p)
                sub_chunk = ""
                for s in sentences:
                    if len(sub_chunk) + len(s) < max_len:
                        sub_chunk += s
                    else:
                        if sub_chunk:
                            chunks.append(sub_chunk.strip())
                        sub_chunk = s
                if sub_chunk:
                    current = sub_chunk
                else:
                    current = ""
            else:
                current = p
    
    if current:
        chunks.append(current.strip())
    
    return chunks if chunks else [text[:max_len]]

def extract_text(file_obj):
    file_name = getattr(file_obj, "name", "") or (file_obj if isinstance(file_obj, str) else "")
    ext = file_name.lower().rsplit(".", 1)[-1] if "." in file_name else ""
    if not ext:
        raise ValueError("ç¼ºå°‘æˆ–ä¸æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å")

    if hasattr(file_obj, "read"):
        data = file_obj.read()
        if hasattr(file_obj, "seek"):
            file_obj.seek(0)
    else:
        with open(file_obj, "rb") as f:
            data = f.read()

    text = ""
    try:
        if ext == "pdf":
            reader = pypdf.PdfReader(io.BytesIO(data))
            for page in reader.pages:
                text += (page.extract_text() or "") + "\n"
        elif ext == "epub":
            with tempfile.NamedTemporaryFile(delete=False, suffix=".epub") as tmp:
                tmp.write(data)
                tmp_path = tmp.name
            try:
                book = epub.read_epub(tmp_path)
                for item in list(book.get_items_of_type(ebooklib.ITEM_DOCUMENT)):
                    soup = BeautifulSoup(item.get_content(), "html.parser")
                    text += soup.get_text() + "\n"
            finally:
                os.remove(tmp_path)
        elif ext in ["docx", "doc"]:
            doc = Document(io.BytesIO(data))
            text = "\n".join([p.text for p in doc.paragraphs])
        else:
            text = data.decode("utf-8", errors="ignore")
    except Exception as e:
        print(f"[extract] {file_name} error: {e}")
    return text

@st.cache_resource
def get_client(api_key):
    return genai.Client(api_key=api_key)

def parse_json_response(text):
    """å®‰å…¨è§£æ LLM è¿”å›çš„ JSON"""
    text = text.replace("```json", "").replace("```", "").strip()
    # å°è¯•æ‰¾åˆ° JSON æ•°ç»„æˆ–å¯¹è±¡
    for start_char, end_char in [("[", "]"), ("{", "}")]:
        start = text.find(start_char)
        end = text.rfind(end_char) + 1
        if start != -1 and end > start:
            try:
                return json.loads(text[start:end])
            except:
                continue
    return [] if "[" in text else {}

# ============================================
# é˜¶æ®µ1ï¼šæ•æ„Ÿç‚¹æ‰«æ
# ============================================

def scan_sensitive_points(chunk_data, client, model):
    """æ‰«ææ–‡æœ¬å—ä¸­çš„æ•æ„Ÿç‚¹"""
    i, text = chunk_data
    prompt = SENSITIVE_SCAN_PROMPT.format(text=text)
    
    try:
        resp = client.models.generate_content(model=model, contents=prompt)
        points = parse_json_response(resp.text)
        if isinstance(points, list):
            for p in points:
                p["source_chunk"] = i
                p["source_text"] = text[:200] + "..." if len(text) > 200 else text
            return points
    except Exception as e:
        print(f"[scan chunk {i}] error: {e}")
    return []

# ============================================
# é˜¶æ®µ2ï¼šå…³ç³»æ„å»º
# ============================================

def build_relations(sensitive_points, text, client, model):
    """åŸºäºæ•æ„Ÿç‚¹æ„å»ºå…³ç³»ç½‘ç»œ"""
    if not sensitive_points:
        return []
    
    points_summary = json.dumps(sensitive_points[:20], ensure_ascii=False, indent=2)
    prompt = RELATION_BUILD_PROMPT.format(
        sensitive_points=points_summary,
        text=text[:3000]
    )
    
    try:
        resp = client.models.generate_content(model=model, contents=prompt)
        relations = parse_json_response(resp.text)
        return relations if isinstance(relations, list) else []
    except Exception as e:
        print(f"[build relations] error: {e}")
    return []

# ============================================
# éšå–»è¯†åˆ«
# ============================================

def detect_metaphors(text, client, model):
    """æ£€æµ‹éšå–»å’Œæš—ç¤º"""
    prompt = METAPHOR_PROMPT.format(text=text[:2500])
    
    try:
        resp = client.models.generate_content(model=model, contents=prompt)
        result = parse_json_response(resp.text)
        return result if isinstance(result, dict) else {}
    except Exception as e:
        print(f"[metaphor] error: {e}")
    return {}

# ============================================
# å…³ç³»æ¨ç†
# ============================================

def infer_relations(existing_relations, client, model):
    """æ¨ç†éšå«å…³ç³»"""
    if len(existing_relations) < 3:
        return {}
    
    relations_summary = json.dumps(existing_relations[:30], ensure_ascii=False, indent=2)
    prompt = INFERENCE_PROMPT.format(existing_relations=relations_summary)
    
    try:
        resp = client.models.generate_content(model=model, contents=prompt)
        result = parse_json_response(resp.text)
        return result if isinstance(result, dict) else {}
    except Exception as e:
        print(f"[inference] error: {e}")
    return {}

# ============================================
# æ„å»ºå¯è§†åŒ–å›¾è°±
# ============================================

def build_graph(relations, sensitive_points, inference_result):
    """æ„å»ºå¸¦é£é™©ç­‰çº§çš„çŸ¥è¯†å›¾è°±"""
    G = nx.DiGraph()
    
    # ç»Ÿè®¡å®ä½“é£é™©ç­‰çº§
    entity_risks = defaultdict(lambda: {"high": 0, "medium": 0, "low": 0})
    
    for r in relations:
        head = r.get("head", "")
        tail = r.get("tail", "")
        risk = r.get("risk_level", "low")
        if head:
            entity_risks[head][risk] += 1
        if tail:
            entity_risks[tail][risk] += 1
    
    # ä»æ•æ„Ÿç‚¹æå–å®ä½“é£é™©
    for p in sensitive_points:
        risk = p.get("risk_level", "low")
        for entity in p.get("entities", []):
            entity_risks[entity][risk] += 1
    
    def get_entity_risk(entity):
        risks = entity_risks.get(entity, {"high": 0, "medium": 0, "low": 0})
        if risks["high"] > 0:
            return "high"
        elif risks["medium"] > 0:
            return "medium"
        return "low"
    
    def get_dimension_color(relation):
        """æ ¹æ®å…³ç³»ç±»å‹è¿”å›é¢œè‰²"""
        rel_type = relation.get("relation_type", "neutral")
        if rel_type == "attack":
            return "#ff4444"
        elif rel_type == "support":
            return "#44bb44"
        elif rel_type == "imply":
            return "#aa44ff"
        elif rel_type == "oppose":
            return "#ffaa00"
        return "#7f8ea3"
    
    # æ·»åŠ èŠ‚ç‚¹å’Œè¾¹
    for r in relations:
        head = r.get("head", "").strip()
        tail = r.get("tail", "").strip()
        relation_text = r.get("relation", "")
        
        if not head or not tail:
            continue
        
        head_risk = get_entity_risk(head)
        tail_risk = get_entity_risk(tail)
        
        head_style = RISK_LEVELS[head_risk]
        tail_style = RISK_LEVELS[tail_risk]
        
        # æ·»åŠ èŠ‚ç‚¹
        G.add_node(head, 
            label=head, 
            color=head_style["color"],
            size=head_style["size"],
            borderWidth=head_style["border"],
            title=f"é£é™©ç­‰çº§: {head_style['name']}"
        )
        G.add_node(tail, 
            label=tail, 
            color=tail_style["color"],
            size=tail_style["size"],
            borderWidth=tail_style["border"],
            title=f"é£é™©ç­‰çº§: {tail_style['name']}"
        )
        
        # æ·»åŠ è¾¹
        edge_color = get_dimension_color(r)
        rel_type = r.get("relation_type", "neutral")
        dashes = rel_type == "imply"  # æš—ç¤ºå…³ç³»ç”¨è™šçº¿
        
        label = relation_text if len(relation_text) <= 20 else relation_text[:17] + "..."
        G.add_edge(head, tail, 
            label=label,
            color=edge_color,
            dashes=dashes,
            arrows="to",
            title=r.get("evidence", "")[:100] if r.get("evidence") else ""
        )
    
    # æ·»åŠ æ¨ç†å‡ºçš„å…³ç³»
    if inference_result and "inferred_relations" in inference_result:
        for r in inference_result["inferred_relations"]:
            head = r.get("head", "").strip()
            tail = r.get("tail", "").strip()
            if head and tail and not G.has_edge(head, tail):
                if head not in G:
                    G.add_node(head, label=head, color="#7f8ea3", size=15)
                if tail not in G:
                    G.add_node(tail, label=tail, color="#7f8ea3", size=15)
                G.add_edge(head, tail,
                    label=r.get("relation", "æ¨ç†å…³è”"),
                    color="#9966ff",
                    dashes=True,
                    arrows="to",
                    title=f"ç½®ä¿¡åº¦: {r.get('confidence', 0.5)}"
                )
    
    return G

# ============================================
# ç”ŸæˆæŠ¥å‘Š
# ============================================

def generate_report(sensitive_points, relations, inference_result, metaphor_results):
    """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    rpt = "# ğŸ” DeepGraph Pro v3 æ•æ„Ÿå†…å®¹åˆ†ææŠ¥å‘Š\n\n"
    
    # ç»Ÿè®¡æ‘˜è¦
    high_count = sum(1 for p in sensitive_points if p.get("risk_level") == "high")
    medium_count = sum(1 for p in sensitive_points if p.get("risk_level") == "medium")
    low_count = sum(1 for p in sensitive_points if p.get("risk_level") == "low")
    
    rpt += "## ğŸ“Š é£é™©ç»Ÿè®¡\n\n"
    rpt += f"- ğŸ”´ é«˜å±æ•æ„Ÿç‚¹: {high_count}\n"
    rpt += f"- ğŸŸ  ä¸­å±æ•æ„Ÿç‚¹: {medium_count}\n"
    rpt += f"- ğŸŸ¢ ä½å±æ•æ„Ÿç‚¹: {low_count}\n"
    rpt += f"- ğŸ“ˆ å…³ç³»æ€»æ•°: {len(relations)}\n\n"
    
    # ç»´åº¦åˆ†å¸ƒ
    dim_counts = defaultdict(int)
    for p in sensitive_points:
        dim = p.get("dimension", "unknown")
        dim_counts[dim] += 1
    
    rpt += "## ğŸ¯ æ•æ„Ÿç»´åº¦åˆ†å¸ƒ\n\n"
    for dim, info in SENSITIVE_DIMENSIONS.items():
        count = dim_counts.get(dim, 0)
        if count > 0:
            rpt += f"- **{info['name']}**: {count} å¤„\n"
    rpt += "\n"
    
    # é«˜å±æ•æ„Ÿç‚¹è¯¦æƒ…
    high_points = [p for p in sensitive_points if p.get("risk_level") == "high"]
    if high_points:
        rpt += "## ğŸš¨ é«˜å±æ•æ„Ÿç‚¹è¯¦æƒ…\n\n"
        for i, p in enumerate(high_points[:10], 1):
            dim = p.get("dimension", "unknown")
            dim_name = SENSITIVE_DIMENSIONS.get(dim, {}).get("name", dim)
            rpt += f"### {i}. [{dim_name}]\n"
            rpt += f"**åŸæ–‡**: {p.get('content', '')[:200]}...\n\n"
            rpt += f"**è§£è¯»**: {p.get('interpretation', '')}\n\n"
            rpt += f"**æ¶‰åŠå®ä½“**: {', '.join(p.get('entities', []))}\n\n"
            rpt += "---\n\n"
    
    # æ ¸å¿ƒçŸ›ç›¾
    if inference_result and inference_result.get("core_conflicts"):
        rpt += "## âš”ï¸ æ ¸å¿ƒçŸ›ç›¾\n\n"
        for conflict in inference_result["core_conflicts"]:
            rpt += f"- {conflict}\n"
        rpt += "\n"
    
    # é˜µè¥åˆ†æ
    if inference_result and inference_result.get("camps"):
        rpt += "## ğŸ´ é˜µè¥åˆ†æ\n\n"
        for camp in inference_result["camps"]:
            rpt += f"**{camp.get('name', 'æœªå‘½å')}**: {', '.join(camp.get('members', []))}\n"
            rpt += f"- ç«‹åœº: {camp.get('stance', '')}\n\n"
    
    # éšå–»åˆ†æ
    if metaphor_results and metaphor_results.get("has_metaphor"):
        rpt += "## ğŸ­ éšå–»/æš—ç¤ºåˆ†æ\n\n"
        for m in metaphor_results.get("metaphors", [])[:5]:
            rpt += f"- **è¡¨é¢**: {m.get('surface', '')}\n"
            rpt += f"  - **å®é™…å«ä¹‰**: {m.get('actual_meaning', '')}\n"
            rpt += f"  - **æŒ‡å‘ç›®æ ‡**: {m.get('target', '')}\n"
            rpt += f"  - **æŠ€å·§**: {m.get('technique', '')}\n\n"
    
    return rpt

# ============================================
# ä¸»æµç¨‹
# ============================================

def main_run(files, api_key, model):
    client = get_client(api_key)
    
    # æå–æ–‡æœ¬
    all_text = ""
    for f in files:
        txt = extract_text(f)
        if len(txt) > 100:
            all_text += txt + "\n\n"
    
    if not all_text:
        return None, "âŒ æ–‡ä»¶å†…å®¹ä¸ºç©ºæˆ–è¯»å–å¤±è´¥", [], {}
    
    # æ™ºèƒ½åˆ†å—
    chunks = [(i, c) for i, c in enumerate(smart_split(all_text)) if len(c) > 50]
    
    if not chunks:
        return None, "âŒ æ–‡ä»¶å†…å®¹è¿‡çŸ­", [], {}
    
    # ===== é˜¶æ®µ1: æ•æ„Ÿç‚¹æ‰«æ =====
    st.info(f"ğŸ” é˜¶æ®µ1: æ‰«æ {len(chunks)} ä¸ªæ–‡æœ¬å—çš„æ•æ„Ÿå†…å®¹...")
    bar = st.progress(0)
    all_sensitive_points = []
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as exe:
        futures = [exe.submit(scan_sensitive_points, c, client, model) for c in chunks]
        for i, f in enumerate(concurrent.futures.as_completed(futures)):
            if result := f.result():
                all_sensitive_points.extend(result)
            bar.progress((i + 1) / len(chunks))
    
    st.success(f"âœ… é˜¶æ®µ1å®Œæˆ: å‘ç° {len(all_sensitive_points)} ä¸ªæ•æ„Ÿç‚¹")
    
    # ===== é˜¶æ®µ2: å…³ç³»æ„å»º =====
    st.info("ğŸ”— é˜¶æ®µ2: æ„å»ºæ•æ„Ÿå®ä½“å…³ç³»ç½‘ç»œ...")
    all_relations = build_relations(all_sensitive_points, all_text, client, model)
    st.success(f"âœ… é˜¶æ®µ2å®Œæˆ: æ„å»º {len(all_relations)} æ¡å…³ç³»")
    
    # ===== éšå–»è¯†åˆ« =====
    st.info("ğŸ­ è¯†åˆ«éšå–»å’Œæš—ç¤º...")
    # å¯¹é«˜å±æ•æ„Ÿç‚¹è¿›è¡Œéšå–»åˆ†æ
    high_risk_texts = [p.get("content", "") for p in all_sensitive_points if p.get("risk_level") == "high"]
    metaphor_text = "\n---\n".join(high_risk_texts[:5]) if high_risk_texts else all_text[:2000]
    metaphor_results = detect_metaphors(metaphor_text, client, model)
    
    # ===== å…³ç³»æ¨ç† =====
    st.info("ğŸ§  æ¨ç†éšå«å…³ç³»...")
    inference_result = infer_relations(all_relations, client, model)
    
    # ===== æ„å»ºå›¾è°± =====
    st.info("ğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è°±...")
    G = build_graph(all_relations, all_sensitive_points, inference_result)
    
    # ===== ç”ŸæˆæŠ¥å‘Š =====
    report = generate_report(all_sensitive_points, all_relations, inference_result, metaphor_results)
    
    return G, report, all_sensitive_points, inference_result

# ============================================
# ç•Œé¢
# ============================================

st.title("ğŸ” DeepGraph Pro v3")
st.markdown("**æ•æ„Ÿå†…å®¹æ·±åº¦åˆ†æç³»ç»Ÿ** - è¯†åˆ«ä¸ç¬¦åˆå®£ä¼ å£å¾„çš„éšæ™¦è¡¨è¾¾")

with st.sidebar:
    st.header("âš™ï¸ é…ç½®")
    api_key = st.text_input("Google API Key", type="password")
    model_id = st.text_input("Model ID", value="gemini-2.0-flash-exp")
    
    st.markdown("---")
    st.markdown("""
    ### ğŸ¨ é£é™©ç­‰çº§å›¾ä¾‹
    - ğŸ”´ **é«˜å±**: æ˜ç¡®è¿åå£å¾„
    - ğŸŸ  **ä¸­å±**: éœ€è¦å®¡æ ¸
    - ğŸŸ¢ **ä½å±**: å¯ä»¥å¿½ç•¥
    
    ### ğŸ¯ æ•æ„Ÿç»´åº¦
    - ğŸ“• å†å²è™šæ— 
    - ğŸ“™ æ”¿æ²»ç«‹åœº
    - ğŸ“’ èˆ†æƒ…ç…½åŠ¨
    - ğŸ“˜ æ•æ„Ÿäº‹ä»¶
    """)

col1, col2 = st.columns([1, 2.2])

with col1:
    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
    files = st.file_uploader("ä¸Šä¼ æ–‡ä»¶ (PDF/DOCX/EPUB/TXT)", accept_multiple_files=True)
    st.markdown("<br>", unsafe_allow_html=True)
    start = st.button("ğŸš€ å¼€å§‹æ·±åº¦åˆ†æ")
    st.markdown("</div>", unsafe_allow_html=True)
    
    if st.session_state.processed:
        st.download_button("ğŸ“¥ ä¸‹è½½å›¾è°± HTML", st.session_state.graph_html, "graph.html", "text/html")
        st.download_button("ğŸ“¥ ä¸‹è½½åˆ†ææŠ¥å‘Š", st.session_state.report_txt, "report.md", "text/markdown")

with col2:
    status = "å°±ç»ª"
    if start:
        status = "åˆ†æä¸­"
    if st.session_state.processed:
        status = "å®Œæˆ"
    
    st.markdown(
        f"""
        <div class='glass-card' style='padding:12px 16px; display:flex; gap:10px; align-items:center;'>
          <span style='padding:6px 12px; border-radius:999px; background:rgba(74,224,200,0.18); color:#4ae0c8; font-weight:800;'>{status}</span>
          <span style='color:#cbd5e1;'>ä¸¤é˜¶æ®µæŠ½å– Â· éšå–»è¯†åˆ« Â· å…³ç³»æ¨ç† Â· é£é™©åˆ†çº§</span>
        </div>
        """,
        unsafe_allow_html=True,
    )
    
    if start:
        if not api_key or not files:
            st.error("è¯·å¡«å…¥ API Key å¹¶ä¸Šä¼ æ–‡ä»¶")
        else:
            with st.spinner("æ·±åº¦åˆ†æä¸­..."):
                G, report, sensitive_points, inference = main_run(files, api_key, model_id)
                if G and len(G.nodes()) > 0:
                    net = Network(
                        height="750px",
                        width="100%",
                        bgcolor="#0c1224",
                        font_color="#e6edf7",
                        directed=True,
                    )
                    net.from_nx(G)
                    net.set_options("""
{
  "physics": {
    "enabled": true,
    "solver": "forceAtlas2Based",
    "forceAtlas2Based": {
      "gravitationalConstant": -120,
      "centralGravity": 0.008,
      "springLength": 150,
      "springConstant": 0.08,
      "damping": 0.85,
      "avoidOverlap": 1.0
    },
    "stabilization": { "enabled": true, "iterations": 1000, "updateInterval": 25 }
  },
  "edges": { "smooth": {"type": "continuous"} },
  "interaction": { "dragNodes": true, "hover": true, "navigationButtons": true, "tooltipDelay": 100 }
}
                    """)
                    st.session_state.graph_html = net.generate_html()
                    st.session_state.report_txt = report
                    st.session_state.sensitive_points = sensitive_points
                    st.session_state.processed = True
                    st.rerun()
                elif report:
                    st.warning(report)
    
    if st.session_state.processed:
        # æ˜¾ç¤ºæ•æ„Ÿç‚¹ç»Ÿè®¡
        points = st.session_state.sensitive_points
        high = sum(1 for p in points if p.get("risk_level") == "high")
        medium = sum(1 for p in points if p.get("risk_level") == "medium")
        
        cols = st.columns(3)
        with cols[0]:
            st.metric("ğŸ”´ é«˜å±", high)
        with cols[1]:
            st.metric("ğŸŸ  ä¸­å±", medium)
        with cols[2]:
            st.metric("ğŸ“Š æ€»æ•æ„Ÿç‚¹", len(points))
        
        # æ˜¾ç¤ºå›¾è°±
        st.components.v1.html(st.session_state.graph_html, height=750)
        
        # æ˜¾ç¤ºæŠ¥å‘Š
        with st.expander("ğŸ“‹ æŸ¥çœ‹å®Œæ•´åˆ†ææŠ¥å‘Š", expanded=False):
            st.markdown(st.session_state.report_txt)
